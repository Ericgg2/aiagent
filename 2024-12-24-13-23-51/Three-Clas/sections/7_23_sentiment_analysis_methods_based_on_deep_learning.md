
Deep learning achieves feature extraction and learning from data through multi-layer neural networks, and in recent years, it has shown significant advantages in text sentiment analysis. Representative models include Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), among others.

Research has found that introducing attention mechanisms into deep learning models can significantly enhance the model's ability to identify key emotional information in text. For example, one study combined attention mechanisms with dynamic CNN and Bidirectional Gated Recurrent Units (BiGRU) to strengthen the model's ability to extract emotional features from text. Another study incorporated attention mechanisms into RNNs to further improve sentiment classification accuracy.

In recent years, pre-trained models such as BERT have driven the development of text sentiment analysis. Pre-trained models improve sentiment analysis performance by pre-training general models on large-scale unlabeled corpora and then fine-tuning them for specific tasks. For example, combining BERT with LSTM allows for more fine-grained sentiment classification. Additionally, some studies have used BERT?s dynamic representations of Weibo text, extracting contextual features and processing them with Bidirectional LSTM and attention mechanisms, while CNN captures local sentiment features to effectively perform sentiment polarity classification. To further enhance model performance, other studies have integrated semantic information from different hidden layers of BERT to generate richer feature vectors, thereby improving the model's ability to recognize sentiment tendencies.

In summary, deep learning-based sentiment analysis methods have progressively become mainstream, bringing new breakthroughs to sentiment analysis research in the realm of social networks. The introduction of pre-trained models has further expanded the boundaries of sentiment analysis technology.[6, 7]
