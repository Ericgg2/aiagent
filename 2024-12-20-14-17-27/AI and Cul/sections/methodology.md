faces
important
limitations
regarding
the
temporal
relationship
between
model
training
and
test
content.
Using
the
2023
version
of
the
Chinese
National
Social
Work
Examination,
which
coincides
with
model
training
cutoff
dates,
creates
uncertainty
about
whether
models
were
inadvertently
exposed
to
exam
questions
during
training.
While
we
took
steps
to
use
only28
exam
guide
materials,
we
cannot
definitively
determine
if
performance
reflects
true
knowledge
or
pattern
matching
from
training
data.
A
significant
limitation
is
our
reliance
on
a
professional
licensing
examination
as
the
primary
assessment
tool.
While
the
CNSWE
provides
a
standardized
measure
of
basic
professional
knowledge,
it
may
not
fully
capture
the
nuanced
understanding
required
for
real-world
social
work
practice.
The
multiple-choice
format,
even
with
expert
review
of
explanations,
cannot
assess
important
aspects
of
professional
competence,
such
as
clinical
judgment,
cultural
sensitivity,
and
ethical
decision-making
in
complex
scenarios.
Further
benchmarks
incorporating
case
studies,
open-ended
responses,
and
practical
assessments
would
provide
a
more
comprehensive
evaluation
of
model
capabilities
in
social
work
contexts.
Our
study
has
limitations
in
its
binary
classification
of
"Chinese"
versus
"Western"
models,
which
oversimplifies
the
complex
cultural
influences
on
model
development
and
performance.
While
we
identified
important
architectural
limitations
in
mathematical
computation
and
logical
reasoning,
these
findings
represent
only
a
snapshot
in
time
given
the
rapid
evolution
of
AI
capabilities.
During
our
study
period,
companies
like
DeepSeek,
OpenAI,
and
Alibaba
released
new
models
with
enhanced
multi-step
reasoning
abilities,
demonstrating
the
field's
swift
progress.
This
rapid
advancement,
coupled
with
the
dynamic
nature
of
Chinese
social
work
practice,
suggests
the
need
for
ongoing
evaluation
using
diverse
assessment
approaches
to
fully
understand
these
evolving
technologies'
capabilities
and
limitations.