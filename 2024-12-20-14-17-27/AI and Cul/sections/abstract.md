Objective:
This
study
examines
how
well
leading
Chinese
and
Western
large
language
models
understand
and
apply
Chinese
social
work
principles,
focusing
on
their
foundational
knowledge
within
a
non-Western
professional
setting.
We
test
whether
the
cultural
context
in
the
developing
country
influences
model
reasoning
and
accuracy.
Method:
Using
a
published
self-study
version
of
the
Chinese
National
Social
Work
Examination
(160
questions)
covering
jurisprudence
and
applied
knowledge,
we
administered
three
testing
conditions
to
eight
cloud-based
large
language
modelsâ€”four
Chinese
and
four
Western.
We
examined
their
responses
following
official
guidelines
and
evaluated
their
explanations'
reasoning
quality.
Results:
Seven
of
eight
models
surpassed
the
passing
threshold
of
60
points
on
both
test
sections,
with
only
one
model
falling
slightly
below
(59.5)
in
the
applied
knowledge
section.
Chinese
models
performed
stronger
on
jurisprudence
questions
(median
=
77.0
vs.
70.3
for
Western
models)
but
somewhat
lower
on
applied
knowledge
(median
=
65.5
vs.
67.0).
Both
Chinese
and
Western
models
showed
cultural
biases,
particularly
in
scenarios
involving
gender
equality
and
family
dynamics.
Models
demonstrated
a
strong
command
of
professional
terminology
but
often
failed
to
recognize
culturally
specific
intervention
techniques.
Expert
review
revealed
rates
of
valid
reasoning
among
incorrect
answers
ranged
from
16.4%
to
45.0%.
Conclusions:
Chinese
and
Western
models
demonstrate
foundational
knowledge
of
Chinese
social
work
principles,
though
performance
patterns
vary
by
domains
and
question
types.
While
Chinese
models
show
advantages
in
regulatory
content,
Chinese
and
Western
models
struggle
with
culturally
nuanced
practice
scenarios.
These
findings
suggest
that
technical
language
ability
does
not
guarantee
cultural
competence.
The