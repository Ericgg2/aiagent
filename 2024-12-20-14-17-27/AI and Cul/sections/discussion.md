explores
these
themes
through
our
empirical
findings,
considering
their
implications
for
social
work
education,
practice,
and
the
development
of
culturally
responsive
AI
tools.
Cultural
Competency
and
Language
Processing
Our
findings
reveal
a
complex
relationship
between
language
processing
and
cultural
understanding
in
AI
systems.
First,
the
models'
competence
varies
in
handling
cultural
and
policy24
content.
While
both
Chinese
and
Western
models
demonstrated
strong
Chinese
language
competence,
Chinese
models
excelled
specifically
in
jurisprudence
questions
but
showed
no
advantage
in
applied
knowledge
scenarios.
This
pattern
challenges
assumptions
about
locally
developed
AI
models'
superiority
in
handling
cultural
content.
Despite
their
primary
Chinese
language
training,
Chinese
models'
advantage
was
limited
to
formal
legal
and
policy
content,
likely
reflecting
the
prevalence
of
official
documents
and
regulatory
materials
in
their
training
data.
Moreover,
our
study
reveals
a
notable
distinction
in
the
models'
ability
to
recognize
cultural-specific
professional
techniques,
particularly
identifying
group
summarization
methods.
For
example,
when
analyzing
a
group
work
scenario
where
a
social
worker
summarized
collective
insights,
“
通
过
讨
论
，
大
家
认
识
到
自
身
和
周
边
的
力
量
来
源
，
包
括
别
人
的
信
任
和
鼓
励
，
家
人
的
爱
和
朋
友
的
陪
伴
”
(“Through
discussion,
everyone
came
to
realize
the
sources
of
strength
in
themselves
and
their
surroundings,
including
others'
trust
and
encouragement,
family
love,
and
companionship
of
friends”),
Claude
was
the
only
model
that
correctly
identified
this
as
a
professional
summarization
technique
-
a
specialized
skill
in
Chinese
social
work
group
practice.
While
other
models
demonstrated
general
language
comprehension,
they
consistently
failed
to
recognize
the
professional
significance
of
this
summarization
approach,
suggesting
limitations
in
their
understanding
of
culture-specific
social
work
interventions.
This
finding
highlights
the
importance
of
considering
both
professional
practice
competencies
and
linguistic
and
cultural
competencies
when
evaluating
model
performance
in
specialized
fields
like
social
work.
Additionally ,
the
models'
performance
suggests
that
command
of
regulatory
language
does
not
equate
to
deeper
cultural
understanding.
This
disparity
appears
linked
to
training
data
composition,
where
formal
documents
are
well-represented
but
nuanced
case
studies
and
practical
interventions
are
less
common.
This
finding
highlights
the
critical
distinction
between
technical
language
processing
and
genuine
cultural-professional
competence,
raising
important
questions
about
how
training
data
availability
shapes
model
performance
in
specialized
domains.
For
example,
in
a
question
about25
identifying
leadership
qualities
in
a
community
handicraft
group,
ChatGPT
uniquely
identified
“loving
putting
self
in
the
spotlight”
as
a
desirable
leadership
trait,
reflecting
a
Western
cultural
perspective
that
contrasts
sharply
with
Chinese
social
values
that
discourage
individual
prominence.
Such
examples
highlight
how
technical
language
proficiency
does
not
necessarily
translate
to
cultural
competency
in
social
work
practice.
More
concerning,
models
perpetuated
cultural
biases
despite
clear
professional
and
legal
frameworks.
This
was
evident
in
inheritance
rights
scenarios
where
both
sons
and
daughters
had
equal
legal
standing
under
Chinese
law,
several
models
across
both
Chinese
and
Western
origins
exhibited
patriarchal
biases
by
favoring
sons
over
daughters
in
their
explanations
despite
explicit
legal
provisions
for
equal
rights.
These
findings
suggest
that
while
models
can
process
Chinese
language
effectively
at
a
semantic
level,
they
may
inadvertently
strengthen
societal
biases
learned
from
training
data,
raising
important
considerations
for
their
use
in
professional
settings
where
equity
and
social
justice
are
paramount.
Technical
Language
vs.
Professional
Understanding
Our
analysis
revealed
an
important
distinction
between
models'
ability
to
process
Chinese
language
and
their
grasp
of
professional
social
work
concepts.
While
models
demonstrated
a
strong
command
of
Chinese
syntax
and
vocabulary ,
they
often
struggled
to
correctly
understand
professional
terminologies
in
context.
This
was
particularly
evident
in
their
explanations
of
incorrect
answers,
where
models
frequently
showed
valid
linguistic
comprehension
but
failed
to
apply
proper
social
work
principles.
For
instance,
Moonshot
(a
Chinese
model)
demonstrated
this
disconnect
by
citing
sophisticated
Chinese
bureaucratic
terminology
like
“
文
件
精
神
”
(spirit
of
the
official
document)
in
a
jurisprudence
question
without
a
proper
understanding
of
its
meaning
-
language
typically
reserved
for
Communist
Party
and
government
meetings,
which
also
coupled
with
the
lowest
rate
of
valid
reasoning
(16.4%)
for
incorrect
responses
among
all
models.
This
disparity
was
even
more
striking
given
that
Moonshot26
performed
worse
than
most
Western
models
on
jurisprudence
questions.
This
suggests
that
a
facility
with
a
formal
Chinese
language
does
not
necessarily
indicate
deeper
professional
understanding.
Technical
Limitations
and
Performance
Patterns
Our
study
revealed
two
major
limitations
in
how
these
AI
models
handle
complex
social
work
questions.
Both
limitations
stem
from
how
these
models
work:
instead
of
truly
understanding
and
reasoning
through
problems
as
humans
do,
they
predict
what
words
should
come
next
based
on
patterns
they
have
seen
before.
The
first
limitation
became
clear
when
models
needed
to
solve
math
problems.
Consider
this
example
from
our
test:
We
asked
models
to
calculate
a
tax
deduction
for
someone
who
donated
60,000
yuan
while
having
a
taxable
income
of
200,000
yuan,
using
a
30%
threshold.
While
the
models
could
correctly
quote
the
relevant
tax
laws,
they
gave
wildly
different
answers
to
this
straightforward
calculation.
This
happened
because
-
instead
of
doing
math,
models
were
merely
predicting
what
numbers
typically
appear
in
discussions
about
tax
calculations.
The
second
limitation
showed
up
when
models
needed
to
follow
complex
logical
steps.
For
example,
when
given
a
question
about
inheritance
rights
involving
multiple
family
members
across
different
generations,
none
of
our
eight
tested
models
could
correctly
figure
out
who
should
inherit
what.
This
occurred
because
the
models
were
unable
to
maintain
logical
consistency
throughout
the
multiple
steps
of
reasoning;
they
were
simply
predicting
what
typically
follows
in
similar
discussions
about
inheritance.
Supporting,
not
Replacing
Decision-Making
Our
findings
reveal
important
nuances
about
how
LLMs
can
support,
not
replace,
social
work
practice.
While
these
models
demonstrate
strong
capabilities
in
processing
professional
language
and
concepts,
their
performance
on
foundational
knowledge
assessments
suggests
their
greatest
potential
lies
in
helping
practitioners
access
and
apply
professional
knowledge.
Retrieval
augmented
generation
(RAG)
systems
offer
a
particularly
promising
direction.
By
connecting
LLMs'
language
processing27
capabilities
with
expert-curated
knowledge
bases,
we
could
develop
tools
that
deliver
relevant
information
to
practitioners
at
the
point
of
need
(see
Perron
et
al.
2024b).
For
example,
a
RAG
system
could
help
a
practitioner
quickly
access
specific
intervention
strategies,
policy
guidelines,
or
evidence-based
practices
relevant
to
their
current
case,
while
preserving
professional
judgment
about
how
to
apply
this
information.
However,
realizing
this
potential
requires
careful
attention
to
human-computer
interaction
design.
Future
research
should
focus
on
understanding
how
practitioners
seek
and
use
information
in
their
daily
work
and
how
AI-powered
knowledge
systems
can
best
support
these
existing
workflows.
This
includes
investigating
questions
like:
How
should
complex
professional
knowledge
be
organized
and
presented?
What
interface
designs
best
support
practitioners
in
critically
evaluating
and
applying
AI-retrieved
information?
How
can
we
ensure
these
systems
enhance
rather
than
disrupt
the
therapeutic
relationship?
Strengths
and
Limitations
Our
study
makes
several
important
contributions
to
understanding
how
LLMs
perform
in
non-Western
professional
contexts.
Using
a
standardized
national
licensure
examination,
we
provide
the
first
systematic
evaluation
of
Chinese
social
work
knowledge
across
both
Chinese
and
Western
models.
The
dual
focus
on
jurisprudence
and
applied
knowledge
sections
allowed
us
to
distinguish
between
cultural-specific
and
universal
content
understanding.
Furthermore,
our
expert
review
process,
conducted
by
bilingual
social
work
professionals,
provided
valuable
insights
into
how
models
reason
about
professional
concepts
across
cultural
contexts.
However,
our