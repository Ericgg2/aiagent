[1] Y . N. Harari, Sapiens: A brief history of humankind . Random House,
2014.
[2] A. A. Abonamah, M. U. Tariq, and S. Shilbayeh, “On the commodi-
tization of artificial intelligence,” Frontiers in psychology , vol. 12, p.
696346, 2021.
[3] M. Lapan, Deep Reinforcement Learning Hands-On: Apply modern
RL methods, with deep Q-networks, value iteration, policy gradients,
TRPO, AlphaGo Zero and more . Packt Publishing Ltd, 2018.
[4] Y . Chang, X. Wang, J. Wang, Y . Wu, L. Yang, K. Zhu, H. Chen, X. Yi,
C. Wang, Y . Wang et al. , “A survey on evaluation of large language
models,” ACM Transactions on Intelligent Systems and Technology ,
vol. 15, no. 3, pp. 1–45, 2024.
[5] Z. J. Ye and B. Schuller, “Trading through earnings seasons using
self-supervised contrastive representation learning,” arXiv preprint
arXiv:2409.17392 , 2024.
[6] J. Han, Z. Zhang, C. Mascolo, E. Andr ´e, J. Tao, Z. Zhao, and B. W.
Schuller, “Deep learning for mobile mental health: Challenges and
recent advances,” IEEE Signal Processing Magazine , vol. 38, no. 6,
pp. 96–105, 2021.13
[7] Q. Sun, A. Akman, X. Jing, M. Milling, and B. W. Schuller, “Audio-
based kinship verification using age domain conversion,” arXiv preprint
arXiv:2410.11120 , 2024.
[8] J. H. Korteling, G. C. van de Boer-Visschedijk, R. A. Blankendaal,
R. C. Boonekamp, and A. R. Eikelboom, “Human-versus artificial
intelligence,” Frontiers in artificial intelligence , vol. 4, p. 622364, 2021.
[9] S. Iqbal, “The intelligence spectrum: Unraveling the path from ani to
asi,” Journal of Computing & Biomedical Informatics , vol. 7, no. 02,
2024.
[10] E. Yudkowsky, “Creating friendly ai 1.0: The analysis and design of
benevolent goal architectures,” The Singularity Institute, San Francisco,
USA, 2001.
[11] T. Feng, C. Jin, J. Liu, K. Zhu, H. Tu, Z. Cheng, G. Lin, and J. You,
“How far are we from agi,” arXiv preprint arXiv:2405.10313 , 2024.
[12] M. Fahad, T. Basri, M. A. Hamza, S. Faisal, A. Akbar, U. Haider, and
S. E. Hajjami, “The benefits and risks of artificial general intelligence
(agi),” in Artificial General Intelligence (AGI) Security: Smart Appli-
cations and Sustainable Technologies . Springer, 2024, pp. 27–52.
[13] P. Eckersley, “Impossibility and uncertainty theorems in ai value
alignment (or why your agi should not have a utility function),” arXiv
preprint arXiv:1901.00064 , 2018.
[14] W. D’Alessandro, “Deontology and safe artificial intelligence,” Philo-
sophical Studies , pp. 1–24, 2024.
[15] A. Stoel, “The meme of altruism and degrees of personhood,” The
Transhumanism Handbook , pp. 623–629, 2019.
[16] R. J. M. Boyles and J. J. Joaquin, “Why friendly ais won’t be
that friendly: a friendly reply to muehlhauser and bostrom,” AI &
Society , vol. 35, no. 2, pp. 505–507, 2020. [Online]. Available:
https://link.springer.com/article/10.1007/s00146-019-00903-0
[17] R. J. M. Boyles, “Problems with ’friendly ai’,” Ethics and Information
Technology , vol. 23, no. 2, pp. 187–195, 2021. [Online]. Available:
https://link.springer.com/article/10.1007/s10676-021-09595-x
[18] R. Sparrow, “Friendly ai will still be our master. or, why we
should not want to be the pets of super-intelligent computers,”
AI & Society , vol. 39, no. 1, pp. 1–6, 2024. [Online]. Available:
https://link.springer.com/article/10.1007/s00146-023-01698-x
[19] A. Akman and B. W. Schuller, “Audio explainable artificial intelli-
gence: A review,” Intelligent Computing , vol. 2, p. 0074, 2024.
[20] R. Gupta, S. Tanwar, F. Al-Turjman, P. Italiya, A. Nauman, and S. W.
Kim, “Smart contract privacy protection using ai in cyber-physical
systems: tools, techniques and challenges,” IEEE access , vol. 8, pp.
24 746–24 772, 2020.
[21] E. U. Soykan, L. Karacay, F. Karakoc, and E. Tomur, “A survey and
guideline on privacy enhancing technologies for collaborative machine
learning,” IEEE Access , vol. 10, pp. 97 495–97 519, 2022.
[22] A. Triantafyllopoulos, M. Milling, K. Drossos, and B. W. Schuller,
“Fairness and underspecification in acoustic scene classification: The
case for disaggregated evaluations,” arXiv preprint arXiv:2110.01506 ,
2021.
[23] B. Schuller, A. Mallol-Ragolta, A. P. Almansa, I. Tsangko, M. M.
Amin, A. Semertzidou, L. Christ, and S. Amiriparian, “Affective
computing has changed: The foundation model disruption,” 2024.
[Online]. Available: https://arxiv.org/abs/2409.08907
[24] B. Fr ¨oding and M. Peterson, “Friendly ai,” Ethics and Information
Technology , vol. 23, pp. 207–214, 2021.
[25] I. Asimov, I, Robot . New York, NY: Gnome Press, 1950, first appeared
in the short story ”Runaround,” published in 1942.
[26] D. Jordana, “The ethics of ai and robotics: Principles, tools, and
issues,” Ethics and Information Technology , vol. 23, pp. 29–41,
2021. [Online]. Available: https://link.springer.com/article/10.1007/
s10676-020-09556-w
[27] S. L. Anderson, “Asimov’s “three laws of robotics” and machine
metaethics,” AI & Society , vol. 22, no. 4, pp. 477–493,
2008. [Online]. Available: https://link.springer.com/article/10.1007/
s00146-007-0094-5
[28] R. E. Ashcroft, “The common good and the egalitarian research
imperative,” in The Oxford Handbook of Research Ethics , A. S.
Iltis and D. MacKay, Eds. Oxford University Press, 2023, ch. 4,
pp. 69–88. [Online]. Available: https://academic.oup.com/book/57593/
chapter-abstract/469209964?redirectedFrom=fulltext
[29] O. Li, “Problems with “friendly ai”,” Ethics and Information
Technology , vol. 23, no. 3, pp. 543–550, 2021. [Online]. Available:
https://link.springer.com/article/10.1007/s10676-021-09595-x
[30] B. Mittelstadt, “Principles alone cannot guarantee ethical ai,” Nature
Machine Intelligence , vol. 3, pp. 869–872, 2021. [Online]. Available:
https://link.springer.com/article/10.1007/s43681-021-00051-6[31] E. Yudkowsky et al. , “Artificial intelligence as a positive and negative
factor in global risk,” Global catastrophic risks , vol. 1, no. 303, p. 184,
2008.
[32] S. Ghose and collaborators, “The case for animal-friendly ai,” arXiv
preprint , 2024. [Online]. Available: https://arxiv.org/abs/2403.01199
[33] P. Singer and B. Tse, “Ai ethics: The case for including animals,”
Ethics and Information Technology , vol. 24, 2022. [Online]. Available:
https://link.springer.com/article/10.1007/s43681-022-00187-z
[34] E. Yudkowsky, “Coherent extrapolated volition,” Singularity Institute
for Artificial Intelligence , 2004.
[35] N. Soares, B. Fallenstein, S. Armstrong, and E. Yudkowsky, “Corrigi-
bility,” in Workshops at the twenty-ninth AAAI conference on artificial
intelligence , 2015.
[36] I. Gabriel, “Artificial intelligence, values, and alignment,” Minds and
machines , vol. 30, no. 3, pp. 411–437, 2020.
[37] S. Russell, D. Dewey, and M. Tegmark, “Research priorities for robust
and beneficial artificial intelligence,” AI magazine , vol. 36, no. 4, pp.
105–114, 2015.
[38] S. Russell, Human compatible: AI and the problem of control . Penguin
Uk, 2019.
[39] M. Peterson, “The value alignment problem: a geometric approach,”
Ethics and Information Technology , vol. 21, pp. 19–28, 2019.
[40] N. Bostrom, “Hail mary, value porosity, and utility diversification,”
2014.
[41] D. Misselbrook, “Duty, kant, and deontology,” British Journal of
General Practice , vol. 63, no. 609, pp. 211–211, 2013.
[42] C. Mougan and J. Brand, “Kantian deontology meets ai align-
ment: Towards morally robust fairness metrics,” arXiv preprint
arXiv:2311.05227 , 2023.
[43] J. N. Hooker and T. W. N. Kim, “Toward non-intuition-based machine
and artificial intelligence ethics: A deontological approach based on
modal logic,” in Proceedings of the 2018 AAAI/ACM Conference
on AI, Ethics, and Society , ser. AIES ’18. New York, NY , USA:
Association for Computing Machinery, 2018, p. 130–136. [Online].
Available: https://doi.org/10.1145/3278721.3278753
[44] R. Kraut, “Altruism,” in The Stanford Encyclopedia of Philosophy ,
Fall 2020 ed., E. N. Zalta, Ed. Metaphysics Research Lab, Stanford
University, 2020.
[45] T. Maillart, L. Gomez, M. Sharada, D. Chakraborty, and S. Nana-
vati, “Altruistic collective intelligence for the betterment of artificial
intelligence,” in The Routledge Handbook of Artificial Intelligence and
Philanthropy . Routledge, 2024, pp. 344–360.
[46] W. MacAskill, “The definition of effective altruism,” Effective altruism:
Philosophical issues , vol. 2016, no. 7, p. 10, 2019.
[47] G. Restall and G. Russell, “Barriers to implication,” in A Companion
to Philosophical Logic , D. Jacquette, Ed. Wiley-Blackwell, 2010, pp.
243–257. [Online]. Available: https://doi.org/10.1002/9781444310795.
ch13
[48] N. Bostrom and E. Yudkowsky, “The ethics of artificial intelligence,”
inArtificial intelligence safety and security . Chapman and Hall/CRC,
2018, pp. 57–69.
[49] E. Bird, J. Fox-Skelly, N. Jenner, R. Larbey, E. Weitkamp, and
A. Winfield, “The ethics of artificial intelligence: Issues and initiatives,”
European Parliamentary Research Service, Study PE 634.452, 2020.
[Online]. Available: https://www.europarl.europa.eu/RegData/etudes/
STUD/2020/634452/EPRS STU(2020)634452 EN.pdf
[50] F. Kroon, “A utilitarian paradox,” Analysis , vol. 41, no. 2, pp. 107–112,
1981. [Online]. Available: https://philpapers.org/rec/KROAUP
[51] A. van Wynsberghe, “Social robots and the risks to reciprocity,” AI
& Society , vol. 37, no. 2, pp. 479–485, 2022. [Online]. Available:
https://link.springer.com/article/10.1007/s00146-021-01207-y
[52] I. Kant, Groundwork of the Metaphysics of Morals . New York: Harper
& Row, 1785, translated by H. J. Paton in 1948, original publication
1785.
[53] N. Bostrom, Superintelligence: Paths, Dangers, Strategies . Oxford:
Oxford University Press, 2014.
[54] M. Tegmark, “Friendly artificial intelligence: the physics challenge,”
2014. [Online]. Available: https://arxiv.org/abs/1409.0813
[55] N. A. Smuha, “The eu approach to ethics guidelines for trustworthy
artificial intelligence,” Computer Law Review International , vol. 20,
no. 4, pp. 97–106, 2019.
[56] V . Dignum, Responsible artificial intelligence: how to develop and use
AI in a responsible way . Springer, 2019, vol. 2156.
[57] B. Mittelstadt, “Principles alone cannot guarantee ethical ai,” Nature
machine intelligence , vol. 1, no. 11, pp. 501–507, 2019.14
[58] D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman,
and D. Man ´e, “Concrete problems in ai safety,” arXiv preprint
arXiv:1606.06565 , 2016.
[59] D. Gunning and D. Aha, “Darpa’s explainable artificial intelligence
(xai) program,” AI magazine , vol. 40, no. 2, pp. 44–58, 2019.
[60] Q. Sun, A. Akman, and B. W. Schuller, “Explainable artificial
intelligence for medical applications: A review,” 2024. [Online].
Available: https://arxiv.org/abs/2412.01829
[61] M. T. Ribeiro, S. Singh, and C. Guestrin, “” why should i trust you?”
explaining the predictions of any classifier,” in Proceedings of the 22nd
ACM SIGKDD international conference on knowledge discovery and
data mining , 2016, pp. 1135–1144.
[62] E. Lee, D. Braines, M. Stiffler, A. Hudler, and D. Harborne, “Develop-
ing the sensitivity of lime for better machine learning explanation,”
inArtificial Intelligence and Machine Learning for Multi-Domain
Operations Applications , vol. 11006. SPIE, 2019, pp. 349–356.
[63] D. Fryer, I. Str ¨umke, and H. Nguyen, “Shapley values for feature
selection: The good, the bad, and the axioms,” Ieee Access , vol. 9,
pp. 144 352–144 360, 2021.
[64] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and
D. Batra, “Grad-cam: Visual explanations from deep networks via
gradient-based localization,” in Proceedings of the IEEE international
conference on computer vision , 2017, pp. 618–626.
[65] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M ¨uller, and
W. Samek, “On pixel-wise explanations for non-linear classifier deci-
sions by layer-wise relevance propagation,” PloS one , vol. 10, no. 7,
p. e0130140, 2015.
[66] R. Achtibat, M. Dreyer, I. Eisenbraun, S. Bosse, T. Wiegand, W. Samek,
and S. Lapuschkin, “From” where” to” what”: Towards human-
understandable explanations through concept relevance propagation,”
arXiv preprint arXiv:2206.03208 , 2022.
[67] R. Xu, N. Baracaldo, and J. Joshi, “Privacy-preserving machine
learning: Methods, challenges and directions,” 2021. [Online].
Available: https://arxiv.org/abs/2108.04417
[68] E. Frimpong, K. Nguyen, M. Budzys, T. Khan, and A. Michalas,
“Guardml: Efficient privacy-preserving machine learning services
through hybrid homomorphic encryption,” 2024. [Online]. Available:
https://arxiv.org/abs/2401.14840
[69] A. Banse, J. Kreischer, and X. O. i J ¨urgens, “Federated learning with
differential privacy,” 2024. [Online]. Available: https://arxiv.org/abs/
2402.02230
[70] M. T. Hosain, M. R. Abir, M. Y . Rahat, M. F. Mridha, and S. H. Mukta,
“Privacy preserving machine learning with federated personalized
learning in artificially generated environment,” IEEE Open Journal of
the Computer Society , vol. 5, pp. 694–704, 2024.
[71] Z. Ji, Z. C. Lipton, and C. Elkan, “Differential privacy and
machine learning: a survey and review,” 2014. [Online]. Available:
https://arxiv.org/abs/1412.7584
[72] M. K. Yogi and A. Chakravarthy, “A novel user centric privacy mech-
anism in cyber physical system,” Computers & Security , p. 104163,
2024.
[73] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,
“A survey on bias and fairness in machine learning,” ACM computing
surveys (CSUR) , vol. 54, no. 6, pp. 1–35, 2021.
[74] A. Triantafyllopoulos and B. Schuller, “Enrolment-based personalisa-
tion for improving individual-level fairness in speech emotion recog-
nition,” arXiv preprint arXiv:2406.06665 , 2024.
[75] D. Kim, S. Park, S. Hwang, M. Ki, S. Jeon, and H. Byun, “Resampling
strategy for mitigating unfairness in face attribute classification,” in
2020 International Conference on Information and Communication
Technology Convergence (ICTC) . IEEE, 2020, pp. 399–402.
[76] N.-T. Tran, V .-H. Tran, N.-B. Nguyen, T.-K. Nguyen, and N.-M.
Cheung, “On data augmentation for gan training,” IEEE Transactions
on Image Processing , vol. 30, pp. 1882–1897, 2021.
[77] Z. Tang and K. Zhang, “Attainability and optimality: The equalized
odds fairness revisited,” in Conference on Causal Learning and Rea-
soning . PMLR, 2022, pp. 754–786.
[78] S. Tan, Y . Shen, and B. Zhou, “Improving the fairness of deep gen-
erative models without retraining,” arXiv preprint arXiv:2012.04842 ,
2020.
[79] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel, “Fairness
through awareness,” in Proceedings of the 3rd innovations in theoretical
computer science conference , 2012, pp. 214–226.
[80] X. Li, P. Wu, and J. Su, “Accurate fairness: Improving individual fair-
ness without trading accuracy,” in Proceedings of the AAAI Conference
on Artificial Intelligence , vol. 37, no. 12, 2023, pp. 14 312–14 320.[81] S. Pfohl, Y . Xu, A. Foryciarz, N. Ignatiadis, J. Genkins, and N. Shah,
“Net benefit, calibration, threshold selection, and training objectives for
algorithmic fairness in healthcare,” in Proceedings of the 2022 ACM
Conference on Fairness, Accountability, and Transparency , 2022, pp.
1039–1052.
[82] R. W. Picard, Affective Computing . Cambridge, MA: MIT Press, 1997.
[83] P. Ekman and W. V . Friesen, “Felt, false, and miserable smiles,” Journal
of Nonverbal Behavior , vol. 6, pp. 238–252, 1982.
[84] ——, Facial Action Coding System: A Technique for the Measurement
of Facial Movement . Palo Alto, CA: Consulting Psychologists Press,
1978.
[85] B. Schuller, G. Rigoll, and M. Lang, “Hidden markov model-based
speech emotion recognition,” in 2003 IEEE International Confer-
ence on Acoustics, Speech, and Signal Processing, 2003. Proceed-
ings.(ICASSP’03). , vol. 2. Ieee, 2003, pp. II–1.
[86] S. Hengameh, S. Sadjadi, and A. Zadeh, “Biofeedback systems: Ap-
plications in autonomic control for therapeutic settings,” Journal of
Biofeedback and Relaxation Techniques , vol. 45, pp. 156–168, 2015.
[87] Y . Wang, W. Song, W. Tao, A. Liotta, D. Yang, X. Li, S. Gao, Y . Sun,
W. Ge, W. Zhang, and W. Zhang, “A systematic review on affective
computing: Emotion models, databases, and recent advances,” 2022.
[Online]. Available: https://arxiv.org/abs/2203.06935
[88] V . S. Bakkialakshmi and T. Sudalaimuthu, “A survey on affective
computing for psychological emotion recognition,” in 2021 5th In-
ternational Conference on Electrical, Electronics, Communication,
Computer Technologies and Optimization Techniques (ICEECCOT) ,
2021, pp. 480–486.
[89] D. M. Schuller and B. W. Schuller, “A review on five recent and near-
future developments in computational processing of emotion in the
human voice,” Emotion Review , vol. 13, no. 1, pp. 44–50, 2021.
[90] Y . Wang et al. , “Affective computing and emotion-sensing technology
for emotion recognition,” in Applications of Artificial Intelligence in
Additive Manufacturing . Springer, 2021, pp. 281–299. [Online]. Avail-
able: https://link.springer.com/chapter/10.1007/978-3-030-70111-6 16
[91] B. Schuller, M. Lang, and G. Rigoll, “Multimodal emotion recognition
in audiovisual communication,” in Proceedings. IEEE international
conference on multimedia and expo , vol. 1. IEEE, 2002, pp. 745–748.
[92] T. Shi and S.-L. Huang, “Multiemo: An attention-based correlation-
aware multimodal fusion framework for emotion recognition in conver-
sations,” in Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers) , 2023, pp.
14 752–14 766.
[93] J. Wu, J. Wu, Y . Zheng, P. Zhan, M. Han, G. Zuo, and L. Yang, “Mlgat:
Multi-layer graph attention networks for multimodal emotion recogni-
tion in conversations,” Journal of Intelligent Information Systems , pp.
1–17, 2024.
[94] B. Schuller, “Multimodal user state and trait recognition: An overview,”
The Handbook of Multimodal-Multisensor Interfaces: Signal Process-
ing, Architectures, and Detection of Emotion and Cognition-Volume 2 ,
pp. 129–165, 2018.
[95] R. Zatarain Cabada et al. ,Multimodal Affective Computing:
Technologies and Applications in Learning Environments . Cham,
Switzerland: Springer, 2023. [Online]. Available: https://link.springer.
com/book/10.1007/978-3-031-32542-7
[96] Y . Liu, K. Wang, L. Wei, J. Chen, Y . Zhan, D. Tao, and Z. Chen,
“Affective computing for healthcare: Recent trends, applications, chal-
lenges, and beyond,” arXiv preprint arXiv:2402.13589 , 2024.
[97] L. Shu, J. Xie, M. Yang, Z. Li, Z. Li, D. Liao, X. Xu, and X. Yang, “A
review of emotion recognition using physiological signals,” Sensors ,
vol. 18, no. 7, p. 2074, 2018.
[98] M. Dhuheir, A. Albaseer, E. Baccour, A. Erbad, M. Abdallah, and
M. Hamdi, “Emotion recognition for healthcare surveillance systems
using neural networks: A survey,” in 2021 International Wireless
Communications and Mobile Computing (IWCMC) . IEEE, 2021, pp.
681–687.
[99] A. Mallol-Ragolta, S. Liu, N. Cummins, and B. Schuller, “A curriculum
learning approach for pain intensity recognition from facial expres-
sions,” in 2020 15th IEEE international conference on automatic face
and gesture recognition (FG 2020) . IEEE, 2020, pp. 829–833.
[100] D. Yang, A. Alsadoon, P. C. Prasad, A. K. Singh, and A. Elchouemi,
“An emotion recognition model based on facial recognition in virtual
learning environment,” Procedia Computer Science , vol. 125, pp. 2–10,
2018.
[101] I. Lasri, A. R. Solh, and M. El Belkacemi, “Facial emotion recognition
of students using convolutional neural network,” in 2019 third inter-
national conference on intelligent computing in data sciences (ICDS) .
IEEE, 2019, pp. 1–6.15
[102] M. L. Barron-Estrada, R. Zatarain-Cabada, and R. O. Bustillos, “Emo-
tion recognition for education using sentiment analysis.” Res. Comput.
Sci., vol. 148, no. 5, pp. 71–80, 2019.
[103] M. Schr ¨oder, “Emotional speech synthesis: A review,” in Seventh
European Conference on Speech Communication and Technology ,
2001.
[104] S. Yu, A. Androsov, H. Yan, and Y . Chen, “Bridging computer
and education sciences: a systematic review of automated emotion
recognition in online learning environments,” Computers & Education ,
p. 105111, 2024.
[105] D. de Queiroz Cavalcanti, F. Melo, T. Silva, M. Falc ˜ao, M. Caval-
canti, and V . Becker, “Research on brain-computer interfaces in the
entertainment field,” in International Conference on Human-Computer
Interaction . Springer, 2023, pp. 404–415.
[106] P. Huang, “Decoding emotions: Intelligent visual perception for movie
image classification using sustainable ai in entertainment computing,”
Entertainment Computing , vol. 50, p. 100696, 2024.
[107] S. Li, “Application of entertainment e-learning mode based on genetic
algorithm and facial emotion recognition in environmental art and
design courses,” Entertainment Computing , vol. 52, p. 100798, 2025.
[108] M. Spezialetti, G. Placidi, and S. Rossi, “Emotion recognition for
human-robot interaction: Recent advances and future perspectives,”
Frontiers in Robotics and AI , vol. 7, p. 532279, 2020.
[109] R. Stock-Homburg, “Survey of emotions in human–robot interactions:
Perspectives from robotic psychology on 20 years of research,” Inter-
national Journal of Social Robotics , vol. 14, no. 2, pp. 389–411, 2022.
[110] M. Leo, M. Del Coco, P. Carcagni, C. Distante, M. Bernava, G. Pioggia,
and G. Palestra, “Automatic emotion recognition in robot-children
interaction for asd treatment,” in Proceedings of the IEEE International
Conference on Computer Vision Workshops , 2015, pp. 145–153.
[111] L. Zhang, M. Jiang, D. Farid, and M. A. Hossain, “Intelligent facial
emotion recognition and semantic-based topic detection for a humanoid
robot,” Expert Systems with Applications , vol. 40, no. 13, pp. 5160–
5168, 2013.
[112] C. Breazeal, “Emotion and sociable humanoid robots,” International
journal of human-computer studies , vol. 59, no. 1-2, pp. 119–155,
2003.
[113] B. Schuller, S. Steidl, A. Batliner, A. Vinciarelli, K. Scherer,
F. Ringeval, M. Chetouani, F. Weninger, F. Eyben, E. Marchi et al. ,
“The interspeech 2013 computational paralinguistics challenge: Social
signals, conflict, emotion, autism,” in Proceedings INTERSPEECH
2013, 14th Annual Conference of the International Speech Commu-
nication Association, Lyon, France , 2013.
[114] B. Schuller, A. Mallol-Ragolta, A. P. Almansa, I. Tsangko, M. M.
Amin, A. Semertzidou, L. Christ, and S. Amiriparian, “Affective
computing has changed: The foundation model disruption,” arXiv
preprint arXiv:2409.08907 , 2024.
[115] M. Ghandi, M. Blaisdell, and M. Ismail, “Embodied empathy: Using
affective computing to incarnate human emotion and cognition in ar-
chitecture,” International Journal of Architectural Computing , vol. 19,
no. 4, pp. 532–552, 2021.
[116] S. Livingston and M. Risse, “The future impact of artificial intelligence
on humans and human rights,” Ethics & international affairs , vol. 33,
no. 2, pp. 141–158, 2019.
[117] T. Shen, R. Jin, Y . Huang, C. Liu, W. Dong, Z. Guo, X. Wu, Y . Liu,
and D. Xiong, “Large language model alignment: A survey,” arXiv
preprint arXiv:2309.15025 , 2023.