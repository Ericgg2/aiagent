
# *3.1. Design Requirements*

The target users of our framework include data scientists, domain experts, and management personnel across various urban systems. For instance, in the context of our case study using power grid data, grid operators responsible for managing urban energy systems would significantly benefit from this framework.

To address the identified challenges and knowledge gaps, we have established the following design requirements as the foundation of our approach:

- Scalability and Efficiency in Time-Series Analytics: The proposed approach will leverage the Temporal Fusion Transformer (TFT) for its exceptional efficiency and scalability in processing multivariate time-series data. The method will ensure that the architecture adapts seamlessly to datasets of varying dimensions and complexities, providing a robust and versatile framework for diverse analytical scenarios.
- Exploratory Visual Analytics: Advanced visual analytics techniques will be integrated to enhance the exploration and interpretation of multivariate temporal patterns. The framework will feature advanced user interactions, data transformation processes, tailored visual encodings, and coordinated multiple views to effectively represent ensemble and multi-label data. This comprehensive approach aims to uncover intricate patterns and relationships within the data.
- Interactive and Accessible User Interface: Intuitive, interactive web-based tools, such as online visual dashboards, will be developed to facilitate user-driven exploration of temporal data patterns and latent vector embeddings. These tools will provide an accessible and user-friendly platform for dynamic data analysis, empowering users to uncover deeper insights and interact with complex datasets meaningfully and efficiently.
- Enhanced and Customized Visual Encoding: Innovative, customized visual encodings and representations will be designed to facilitate the visualization of multiple facets of the complex latent embeddings generated by the TFT. These visualizations will support the discovery of intricate temporal and feature-level patterns, addressing the limitations of traditional latent space cartography methods and enabling multi-faceted data analysis and interpretation.
- Evaluation and Benchmarking: Validation workflows will be implemented using generative AI models established in previous latent space cartography studies, such as VAE-based models, to benchmark the performance and accuracy of the TFT-based approach. Novel metrics and ensemble visualizations will be designed and employed to comprehensively compare temporal dependencies and feature extraction capabilities across models.
- Multi-label Dependency Exploration: The proposed methods will enable users to visually explore dependencies between multiple labels in multi-label time-series data by analyzing pattern similarities through distance metrics and other measures derived using the TFT. Real-world urban data often encompasses multiple labels created

using taxonomies from different domains, which highlight interactions between diverse physical processes. For example, in power grid data, event signatures frequently involve multiple labels categorized based on various technical or scientific criteria, such as weather impacts, equipment conditions, and operational states. Capturing and visualizing these interdependencies will provide domain scientists with deeper insights and facilitate hypothesis generation.

These design requirements ensure that the proposed framework effectively addresses the challenges in extracting and interpret patterns from complex multivariate temporal data, while offering robust, scalable, and interpretable solutions for analyzing multivariate urban time-series.

![](_page_10_Figure_0.jpeg)

Figure 1: The conceptual design of our proposed framework.

# *3.2. Framework Design*

Our visual analytics framework comprises four key components: data preparation and preprocessing, generative AI models for dimensional reduction, visual analytical dashboards, and validation and evaluation metrics. The overall design of our framework is depicted in Figure 1.

## *3.3. Data Preparation and Preprocessing*

Our framework is designed to analyze multivariate time-series data and can be adapted to facilitate pattern exploration across various disciplines. In this study, we demonstrate the framework's capabilities using power grid data as a showcase. The dataset originates from the Grid Event Signature Library (GESL), a resource developed by Oak Ridge National Laboratory (ORNL), Lawrence Livermore National Laboratory (LLNL), and Pacific Northwest National Laboratory (PNNL) under the U.S. Department of Energy's Office of Electricity. Additional details about this dataset are provided in Section 4.1.

Similar to many compiled time-series datasets, the data collected from GESL consists of time-series measurements from diverse electrical systems provided by various data sources (e.g., utilities, industry, and academia). This diversity results in a heterogeneous structure with varying sampling rates, scales, and feature sets, posing challenges for consistent analysis and classification. All of the data contained in the GESL come from field measurements; no simulated data has been used in this study, or housed in the GESL.

To preprocess the data, we first address its heterogeneity by normalizing all numeric features to a uniform scale. Signals with varying sampling rates are resampled to a common rate—such as 20 ksps for certain providers—using linear interpolation, ensuring temporal consistency across the dataset. The time-series signals are then analyzed for anomalies by calculating differences between consecutive cycles. For example, using data from Provider 1, one cycle corresponds to 333 samples at 60 Hz. Deviations exceeding a predefined threshold are flagged as anomalies, enabling the identification of event-related irregularities.

To isolate baseline behavior, the data are segmented into 1-second intervals, ensuring uniform segment length. For files with insufficient data, padding is applied using the largest identified non-event region. Non-event segments are repeated as needed to achieve the required length, with smooth transitions ensured by aligning with the tail of the existing data. This preserves phase, amplitude, and temporal continuity. This segmentation and padding approach ensures all data segments are consistent and prepared for downstream analysis.

## *3.4. Generative AI Models*

After preprocessing the data, we construct and apply two types of generative models with encoding capabilities: the Temporal Fusion Transformer (TFT) and a Variational Autoencoder (VAE). These models are used to perform dimensionality reduction, capturing multivariate temporal patterns within the time-series data with multiple features by deriving latent vectors across a range of dimensions. The optimal latent dimension is determined through heuristic exploration facilitated by a visual analytics interface. This interface enables users to interact directly with the generative AI models, experiment with different combinations of hyperparameters, and visually explain and interpret the results. In this study, we employed two types of VAEs: a 1D-Convolutional VAE and a VAE-LSTM, which are detailed through the following subsections.

# *3.4.1. TFT*

The Temporal Fusion Transformer (TFT) is a specialized neural network architecture designed for temporal data representation and feature extraction (Lim et al., 2021). The model leverages a Transformer-based framework, starting with a linear input projection layer that maps input features into a high-dimensional embedding space optimized for sequence modeling (Cristian et al., 2024). To preserve temporal order information, positional encodings are incorporated into the embeddings, enabling the model to effectively capture sequential dependencies. In recent studies, the TFT has been widely employed for prediction and forecasting tasks using multivariate time-series data (Lim et al., 2021; Liao, 2024).

In this study, the core of the TFT architecture consists of Transformer encoder layers, which are utilized to model complex temporal dependencies and interactions across the sequence. These layers allow the model to effectively capture both short- and long-term relationships within the temporal data. To aggregate the temporal information, the output of the Transformer encoders undergoes mean pooling across the sequence length, producing a summarized representation. This representation can be further refined through an optional linear projection to generate the final embeddings for each input sample. Our TFT architecture is designed to process batches of temporal data with dimensions corresponding to the batch size, input feature dimension, and sequence length. It outputs latent embeddings that encapsulate both temporal and feature-level characteristics, making them suitable for a range of downstream tasks. In evaluation mode, the trained model computes embeddings for the input data, which are subsequently stored and mapped to corresponding filenames for further analysis. This architecture and workflow enable robust time-series representation learning, feature extraction for temporal prediction models, and domain-specific applications requiring detailed temporal embeddings. By employing Transformer encoders, the TFT demonstrates high expressivity and adaptability, making it particularly effective in capturing intricate temporal dependencies and providing a versatile solution for temporal data analytics.

## *3.4.2. 1D-Convolutional VAE*

In this study, Variational Autoencoders (VAEs) are utilized to learn compact latent representations of multivariate time-series data, with an emphasis on capturing both temporal and feature-level dependencies. The 1D CNN VAE architecture consists of three main components: an encoder, a latent space representation, and a decoder. The encoder employs 1D convolutional layers to extract hierarchical temporal features from the input time series. These convolutional layers are followed by fully connected layers that parameterize the mean and log-variance of the latent space distribution. The latent space is sampled using the reparameterization trick, which allows for differentiability and ensures stable optimization during backpropagation. The decoder reconstructs the original input data from the latent representations using transposed convolutional layers to upsample the data back to its original dimensions.

The training process is driven by a composite loss function that combines Mean Squared Error (MSE), which reconstruction loss, which measures the fidelity of the reconstructed output to the input data, and the Kullback-Leibler (KL) divergence. The KL divergence regularizes the latent space to follow a standard Gaussian distribution, enabling meaningful and compact representations.

The model is optimized over multiple epochs using the Adam optimizer with a low learning rate to ensure training stability. After training, the latent vectors are extracted for all samples, providing a compressed and semantically rich representation of the input time series. These latent vectors are subsequently saved and mapped to corresponding filenames for downstream applications. This implementation offers a robust framework for capturing and compressing the spatiotemporal structure of multivariate time series into a latent embedding space. These embeddings are highly versatile, supporting tasks such as anomaly detection, clustering, and predictive modeling, and demonstrating the effectiveness of the VAE for temporal data representation and feature extraction.

## *3.4.3. VAE with a LSTM Layer*

Building upon the VAE architecture with 1D convolutional layers described earlier, this research also explores a complementary approach by integrating a Variational Autoencoder (VAE) with an LSTM-based architecture. This variant is designed to handle temporal data with a focus on preserving sequential dependencies, making it particularly suited for time-series data with intricate temporal dynamics.

The encoder employs bidirectional LSTM layers to capture both forward and backward temporal relationships in the data. This design ensures a comprehensive understanding of sequential dependencies across the entire time horizon. The sequential output from the LSTM layers is then flattened and passed through a fully connected layer, which parameterizes the latent space by computing the mean and log-variance of the latent distribution. The latent space representation is sampled using the reparameterization trick, facilitating smooth gradient flow during backpropagation while maintaining differentiability. The decoder reconstructs the input sequences from the latent vectors using a combination of fully connected and LSTM layers. This reconstruction pathway is carefully designed to preserve the temporal structure of the original data, ensuring accurate sequence generation.

Similar to the VAE with 1D convolutional layers, the training process optimizes a composite loss function that balances MSE and KL divergence. The model is trained over multiple epochs using the Adam optimizer, with batched data to enhance computational efficiency. After training, the latent vectors are extracted, serving as compressed representations of the input sequences for downstream tasks such as clustering, anomaly detection, or predictive modeling. In addition to handling temporal data, this implementation incorporates metadata processing to enhance analysis. Event tags associated with the input sequences are parsed to generate binary vectors indicating the presence of specific events. These vectors are visually encoded using smooth color gradients, improving interpretability and facilitating the exploration of relationships between latent vectors and metadata. A mapping from filenames to event tags, binary arrays, and associated properties supports detailed metadata analysis, integrating advanced deep learning with visual analytics.

This VAE-LSTM approach complements the VAE with 1D convolutional layers by offering an alternative architecture that excels in tasks requiring explicit modeling of long-term sequential dependencies, thereby enriching the analytical capabilities for temporal data representation and interpretation. Both of them are later used as the benchmark to evaluate the performance of the TFT.

![](_page_14_Figure_1.jpeg)

Figure 2: The overview of the visual analytics interface for exploring multivariate temporal patterns in multi-label power grid data.

# *3.5. Latent Space Visual Analytics*

A visual analytics interface with linked charts and multiple coordinated views has been developed to enable users to visually explore and analyze the latent vectors (embeddings) generated by the TFT and VAEs. An overview of the interface is shown in Figure 2.

Within the interface, we employed customized visual encoding to accomodate the analytical needs and the characteristics of the complex data. Visual encoding, also known as visual representation, refers to the use of graphical elements such as position, color, size, and shape to represent data in a way that enables intuitive exploration and analysis. Given the multilabel nature and complexity of the multivariate time-series data analyzed in our framework, we devised two novel visual representations to enhance existing visualization techniques commonly used in latent space cartography applications. These innovative visual encodings include the Multivariate 2D Latent Vector Map and the Hierarchical

Multi-label Tree.

**(a) User Scenario** – **Exploring a latent vector cluster and examining its individual elements, represented by patterns detected in the data.**

![](_page_15_Figure_3.jpeg)

![](_page_15_Figure_4.jpeg)

![](_page_15_Figure_5.jpeg)

![](_page_15_Figure_6.jpeg)

![](_page_15_Figure_7.jpeg)

Figure 3: Three scenarios are presented to demonstrate the design and user interaction features of the customized visual encoding developed for the proposed framework.

# *3.5.1. Multivariate 2D Latent Vector Map*

The Multivariate 2D Latent Vector Map provides a spatial representation of the latent vectors (embedding) derived from VAE or TFT. High-dimensional latent vectors are projected into a 2D space as latent representation using dimensionality reduction techniques. These techniques include PCA, t-SNE, or UMAP, which can be selected via the visual analytical interface. The visualization features an interactive viewport, resembling web-based map engines like Leaflet, which allows users to explore clusters, outliers, and temporal transitions within the data through interactions such as zooming, panning, and focusing on specific clusters and their elements (2D latent representtion displayed on the map), as depicted in Figure 3a. This representation offers valuable insights into the temporal and feature-level dependencies captured by the models. To prevent visual clutter and ensure users receive the appropriate level of detail, the map dynamically toggles between different visual representations based on the zoom level. At a low zoom level, which provides a global overview of the latent vector distribution, the visualization uses color-coded dots to represent data points. The color-coding options include categorical cluster labels generated by clustering algorithms such as Gaussian Mixture Models (GMM), Density-Based Spatial Clustering of Applications with Noise (DBSCAN), and agglomerative hierarchical clustering (AHC) applied to class labels. These color-coded dots effectively highlight broad patterns and relationships within the data. At higher zoom levels, where users focus on specific regions to examine local latent vector distributions, the visualization employs glyph-based representations (depicted in the blue box in the user scenario b in Figure 3). These glyphs encode multiple class label attributes into the 2D latent vectors, allowing users to explore the relationships, dependencies, and correlations among complex data patterns. The radius of the dot and the glyph is used to encode the duration of the signal event underlying each 2D latent representation.

This enhanced local view aids in identifying potential connections or inconsistencies across multi-label data, fostering a deeper understanding of intricate data patterns and relationships.

# *3.5.2. Hierarchical Multi-label Tree*

The Hierarchical Multi-label Tree encodes the structure of class labels from the multi-label time-series data into a hierarchical tree representation using color-coded bars. Inspired by dendrogram visualizations, this design aims to reveal the hierarchical relationships among class labels while applying a hierarchical color-coding scheme to represent individual class labels according to their respective categories. This visualization helps users understand the relationships between labels, their hierarchical organization, and the underlying patterns associated with different data segments.

Through advanced user interaction techniques, users can select specific bars representing class labels using their cursor. The visualization then highlights all other class labels that co-occur with the selected label, providing an intuitive exploration of label dependencies. Simultaneously, through coordinated views, the Multivariate 2D Latent Vector Map highlights the 2D distribution of latent representations corresponding to data patterns containing the selected class label. This interaction is illustrated in the user scenario (b) in Figure 3. Since the Hierarchical Multilabel Tree is linked to the Multivariate 2D Latent Vector Map, selecting a 2D latent representation on the map will automatically highlight its associated class label in the tree. This bidirectional interaction is demonstrated in the user scenario (a) in Figure 3. By seamlessly linking hierarchical and spatial representations, the tool enables users to drill down into specific subsets of the data while maintaining a contextual overview of the entire dataset, fostering both granular analysis and holistic understanding.

# *3.5.3. Latent Vector Comparison*

To enhance the explainability of the generative AI models, we incorporated an enhanced bar chart into the visual analytics interface. This bar chart allows users to visually compare the latent vectors of the original latent dimensions across different signal event patterns, which are represented as 2D latent projections in the Multivariate 2D Latent Vector Map. The bar chart is also dynamically linked to the Multivariate 2D Latent Vector Map and visualizes the latent vectors of the last two 2D latent representations selected by the user.

The latent vectors of the currently selected 2D latent representation are color-coded, with blue representing positive values and red representing negative values, contrasted against a gray outline that visualizes the latent vector values of the previously selected 2D latent representation. While the absolute values of the latent vectors do not carry inherent physical meaning, the similarity and variability of these vectors—whether across different clusters or within the same cluster—can provide insights into how the TFT or VAE-based model performs dimensional reduction on multivariate time-series data.

Additionally, users can export the latent vectors as files, enabling further analysis to improve the interpretability and interoperability of the AI models. This feature not only facilitates a deeper understanding of the models' decisionmaking processes but also supports advanced analytics for cross-disciplinary applications.

# *3.6. Validation and Evaluation Metrics*

To evaluate the quality of the clusters formed from the latent space vectors generated by the TFT, we developed a comprehensive validation framework comprising three strategies: Internal Validation using quantitative metrics, Human-in-the-Loop Validation leveraging visual analytics and domain expertise, and Relative Validation through comparative analysis of results produced by the two approaches.

# *3.6.1. Internal Validation*

Internal Validation focuses on assessing the quality of clusters using information inherent to the dataset, without reference to external ground truth labels. we employ three widely used clustering evaluation metrics: Silhouette Score, Calinski-Harabasz Score, and Davies-Bouldin Score. These clusters are derived by further dimensional reduction of the latent space vectors using methods such as Principal Component Analysis (PCA), Uniform Manifold Approximation and Projection (UMAP), and t-Distributed Stochastic Neighbor Embedding (t-SNE). The Silhouette Score measures how well-separated the clusters are by comparing intra-cluster cohesion to inter-cluster separation, with higher values indicating better-defined clusters. The Calinski-Harabasz Score evaluates the ratio of between-cluster dispersion to within-cluster dispersion, rewarding well-separated clusters with low internal variance. The Davies-Bouldin Score assesses the average similarity ratio of each cluster to its most similar cluster, with lower values reflecting more compact and distinct clusters. These metrics collectively provide a robust framework for quantitatively assessing the quality of clusters in the reduced-dimensional latent space, enabling the validation of the effectiveness of TFT and VAE in capturing meaningful structures in multivariate time-series data.

## *3.6.2. Human-in-the-loop Validation*

Human-in-the-Loop Validation integrates visual analytics and domain expertise to evaluate the quality and relevance of clusters formed in the latent space. This approach complements the quantitative metrics used in internal validation by leveraging human insight and justification to identify patterns, anomalies, and domain-specific structures that may not be accurately captured by AI models.

To facilitate this process, we employ advanced visualization techniques such as scatter plots enhanced with tailored multivariate visualization features. These enable users to explore and examine the reduced-dimensional representations of latent vectors and embeddings generated by TFT and VAE-based approaches. Dimensionality reduction is performed using methods such as PCA, UMAP, and t-SNE, and is augmented with advanced user interaction capabilities. These features allow users to pan, zoom, and focus on specific regions of the latent vector map through an interactive viewport. Users can further refine their analysis by hovering over individual data points, each representing a latent vector of the multivariate time-series data. This action dynamically triggers the coordinated display of linked charts and views, revealing detailed information such as corresponding labels and associated metadata. These interactive features provide an intuitive and comprehensive framework for users to analyze and interpret the underlying structure of the latent space, enabling deeper insights into complex data.

The visualizations are implemented through a web-based visual dashboard, allowing domain experts to qualitatively assess cluster separability, density, coherence, and the consistency and interrelationships of class labels within each cluster. For instance, in the context of fault diagnosis, domain experts such as grid operators can identify meaningful patterns or outliers within the latent vector representations, uncovering connections to real-world phenomena. One example identified through analyses using our framework is the consistent clustering of grid events involving arcing—a phenomenon of electrical current flow—and jumper failure, which refers to the failure of flexible or rigid conductive cables or connectors. These data-driven insights suggest a potential physical interaction between the two phenomena. This hypothesis can be validated using domain knowledge from the power grid, thereby confirming the AI model's outputs and ensuring alignment with real-world behavior. The insights gained through this iterative, human-centered validation process are instrumental in refining the model and its outputs. By incorporating expert expertise, Humanin-the-Loop Validation ensures that clustering results are not only statistically robust but also contextually meaningful, effectively bridging the gap between computational analysis and domain-specific understanding. This example is later detailed as one of the use cases in Section 4.2.1.

# *3.6.3. Relative Validation*

To ensure the reliability and trustworthiness of the clustering results derived from the TFT and VAE-based methods, we developed an interactive visual analytical interface that enables domain experts to validate and interpret the results. This interface facilitates the integration of class labels with domain knowledge to provide meaningful justifications for the clustering outcomes. Additionally, we employed a relative validation approach to assess the consistency and similarity of the clustering outputs generated by the two methods. This approach utilizes quantitative cluster similarity metrics alongside a specialized visualization technique, known as the correspondence plot, which highlights the alignment and differences between the clustering results. By connecting corresponding points across the two methods, this visualization provides an intuitive way to compare the distributions and structural relationships of clusters, thereby enabling a robust evaluation and enhanced interpretability of clustering performance. The methodological details of our approach are as follows:

- Cluster Similarity Metrics is designed to quantify the similarity between latent vector clusters derived from TFT and VAE by comparing the neighbors of individual latent vectors within their respective clusters. Neighbors are identified using the K-Nearest Neighbors (KNN) algorithm, applied to the 2D distributions of latent vectors after dimensionality reduction using methods such as PCA, t-SNE, and UMAP. Cluster labels are generated using the DBSCAN algorithm, based on the 2D latent vector distributions. A constraint is applied to ensure that only latent vectors with the same cluster label are considered neighbors. The similarity metric is then calculated as a percentage, reflecting the proportion of identical neighbors for each latent vector across the TFT and VAEbased approaches. This approach provides a quantitative measure to assess the consistency and alignment of cluster structures between the TFT and VAE-based methods.
- Correspondence Plot is the visualization technique designed to compare the distribution and clustering of two sets of point clouds by visually mapping corresponding points across the datasets. In our study, we use the correspondence plot to analyze and compare the latent vectors produced by the VAE- and TFT-based approaches. The plot not only highlights the spatial distribution and clustering of points derived from each method but also employs Dynamic Time Warping (DTW)-styled lines to connect corresponding points—latent vectors with the same ID but derived using the two different methods. These DTW-styled lines facilitate shape matching by capturing the similarity or divergence between the geometric shapes and distributions of the two point clouds. By analyzing the directional alignment and distance of these lines, we can statistically assess the deformations and shifts in clustering patterns. This allows us to compare the structural consistency of the clustering outputs produced by the VAE and TFT-based approaches, providing insights into the reliability and robustness of the methods.

The validation results from our case studies are detailed in Subsection 4.3.3, where the outputs of TFT and VAEbased methods are systematically compared across various configurations, including different latent dimensions and dimensionality reduction algorithms.

## 4. Result Discussion

We applied our framework to assist energy scientists and power grid operators in visually exploring patterns within grid data to facilitate fault diagnosis. The use cases are designed to demonstrate the usability and practical benefits of our approach, which leverages visual analytics to place humans in the loop. This approach enables users to supervise and interact with AI applications that increasingly automate data analytics, ensuring greater reliability, interpretability, and decision-making support.

## *4.1. Case Study Background*

The Grid Event Signature Library (GESL) is an open-access repository designed to provide comprehensive, highresolution measurement data for power system events. Sponsored by the U.S. Department of Energy, GESL includes over 5,600 event records, with labeled and unlabeled data from diverse sources, including Phasor Measurement Units (PMUs) and Point-on-Wave (PoW) devices. These datasets encompass a variety of grid behaviors, including transient events like capacitor switching, load shedding, and frequency oscillations, along with ambient operational conditions. The GESL incorporates several key features designed to enhance its utility for research and practical applications. Each event record is enriched with detailed metadata, including sampling rates, event durations, and textual descriptions, ensuring comprehensive contextual information. The repository integrates diverse data types from multiple measurement technologies, such as Phasor Measurement Units (PMUs), Power-over-Wire (PoW) sensors, and specialized GridSweep™ devices, enabling the capture of both sinusoidal and non-sinusoidal grid behaviors. A hierarchical taxonomy is employed to categorize events based on physical and operational phenomena, providing structured labeling that enhances the interpretability and consistency of the datasets. Furthermore, GESL supports the development of AI-driven applications by offering open access to high-quality data, facilitating analysis, training, and benchmarking for researchers and practitioners alike.

The significance of GESL lies in its ability to bridge the gap between operational data and research needs. By offering labeled and unlabeled datasets, it supports applications in event detection, clustering, anomaly analysis, and real-time grid monitoring. Its availability and diversity make it a vital resource for advancing data-driven methodologies in power system analytics and the integration of renewable energy sources.

# *4.2. Use Cases*

We pre-processed and analyzed multiple datasets collected from six GESL providers, and created two use cases to demonstrate the practical value of our proposed method.

## *4.2.1. Inter-pattern Dependency Analysis*

Our proposed visual analytics framework enables users to explore potential interconnections and dependencies between power grid fault event patterns through linked charts and coordinated views (illustrated in Figure 4). The following use case illustrates how a user can interact with the system to analyze complex relationships within the fault event data. The case study is developed using the data and its augmented version from GSEL Provider 1, which includes six data features: three current fields ('Current.Ia', 'Current.Ib', and 'Current.Ic') and three voltage fields ('Voltage.Va', 'Voltage.Vb', and 'Voltage.Vc'). The dataset also includes a timestamp column, 'Time µs', which provides the temporal context for the time-series data. These six features form the multivariate time-series data used for analysis in the study.

![](_page_21_Figure_1.jpeg)

Figure 4: Use Case 1 and 2: Deducing potential interconnections and dependencies between different fault event patterns, and facilitate the imputation of missing labels for certain fault event patterns.

Step 1: Selecting a Class Label of Interest: The user begins by interacting with the Hierarchical Multi-label Tree

to select a class label of interest. In this scenario, the user selects the class label "Arching". Upon selection, the visualization automatically highlights the co-occurring class label "Jumper", which frequently appears alongside the selected class label in the fault event data. This linked interaction provides an immediate understanding of class label relationships.

- Step 2: Visualizing Latent Representations: Following the class label selection, the Multivariate 2D Latent Vector Map automatically highlights the corresponding 2D latent representations of the fault events. These representations are derived by reducing the dimensionality of the multivariate time-series data using the Temporal Fusion Transformer (TFT) model. In this case, the user selects t-SNE as the dimensionality reduction method to project the high-dimensional TFT latent vectors (e.g., 640 dimensions) into a 2D space. This projection allows users to observe the spatial distribution and relationships of the latent representations, offering insights into potential dependencies and patterns.
- Step 3: Exploring Spatial Relationships and Dependencies The user zooms into the clusters on the 2D latent vector map to examine their spatial organization and identify neighboring clusters with different class labels. This spatial proximity may reveal potential interconnections and dependencies between fault event patterns. In this scenario, the latent vectors for the "Arching" and "Jumper" fault events are observed to be spatially close to neighboring clusters representing other class labels, such as "Local/Power System Failure" (CP/SL), "Interrupting Devices - Fuse" (IF), "Non-specific Transformer Failure" (TN), and "Event Deterioration" (DE).
- Step 4: Deduction The spatial proximity of these clusters suggests similarities or correlations in the underlying fault patterns, which may indicate shared causes or interdependent events. Such insights can be further interpreted and explained using power grid domain knowledge to uncover relationships between different fault types, such as equipment failures, system interruptions, or signal deterioration.

This use case highlights the effectiveness of our framework in integrating generative AI models with interactive visual analytics. By linking the Hierarchical Multi-label Tree with the Multivariate 2D Latent Vector Map, the system allows users to dynamically explore relationships between fault event patterns. The framework not only facilitates the identification of co-occurring fault events but also supports the discovery of hidden dependencies and anomalies within the data. This human-in-the-loop approach ensures that power grid operators and energy scientists can make informed decisions, improving fault diagnosis and grid reliability. The domain knowledge justifications for the datadriven dependencies between various fault class labels are further elaborated in Section 4.3.2.

# *4.2.2. Imputation of Missing Fault Class Labels*

Our framework demonstrates significant value in supporting the imputation of missing fault class labels by leveraging its ability to deduce signal event patterns with incomplete records, such as EN (Non-specific Equipment Failure), from neighboring events' class labels. This user scenario is demonstrated in task D in Figure 4. By analyzing the spatial proximity of latent representations in the Multivariate 2D Latent Vector Map, the framework identifies relationships between events with missing or ambiguous labels and adjacent well-defined class labels, such as EA (Arching), OU (Jumper Failure), or DE (Equipment Deterioration). This approach allows users to infer the most likely fault class for data points lacking annotations, based on shared latent features and clustering behavior in the reduced-dimensional space. By incorporating domain knowledge and these derived dependencies, the framework facilitates accurate label imputation, enhancing the completeness and reliability of fault datasets. This capability is particularly valuable for training AI models, improving the interpretability of power grid fault analyses, and addressing data gaps in real-world operational contexts.

With the ability to visualize the latent vectors of data patterns with missing labels and compare them to the 2D latent representations of neighboring data patterns, our proposed visual analytics methods provide a more explainable approach for facilitating missing label imputation. By incorporating human expertise into the loop through latent vector visualization, our approach enhances the interpretability of AI models, fostering greater trust in the results and significantly improving the reliability of the imputation process.

## *4.2.3. Model Parameter Tuning*

The proposed visual analytics methods provide a powerful interface for visually comparing and assessing the quality of clusters generated from the TFT's dimensional reduction of multivariate time-series data. By allowing users to explore the results under different configurations, such as varying the latent dimensions or the dimensional reduction methods used to project high-dimensional latent vectors into 2D representations, the interface offers a flexible and intuitive way to evaluate model performance. Users can dynamically adjust configurations through the interface and visually analyze how these changes impact the clustering results.

As demonstrated in our use case with signal event data from Provider 4, we compared clusters produced by TFT combined with three dimensional reduction methods that include PCA, t-SNE, and UMAP, under two latent dimensions (8 and 256). This comparative analysis revealed distinct differences in cluster quality and separation, enabling a heuristic approach to identify the most effective configurations for dimensional reduction and latent space representation (depiced in Figure 5). Through the visualization, users can identify model configurations that achieve clear separation of signal events with different class labels. For instance, points color-coded in blue represent events labeled as SG (Source, Generator) and CT (Change State, Trip), while points color-coded in orange correspond to events labeled as CS (Change State, Trip). Datasets from Provider 4 and several other providers, which are well-labeled and thoroughly documented, can be used as benchmark datasets to evaluate AI model performance and optimize parameter configurations. In this use case, specific combinations, such as "t-SNE with a latent dimension of 8", can be identified as optimal setups for clustering tasks within our framework, as they produce clusters with minimal overlap between events with different labels.

While the use case focuses on a specific dataset and parameter set, the framework is versatile and supports broader exploration across diverse latent dimensions and configurations. For datasets with missing labels, such as those from Provider 1, users can subset the data with well-recorded event class labels and use this subset to tune model parameters, optimizing clustering performance. Once the model is tuned, the full dataset can be introduced for additional insights and heuristic exploration, enabling users to uncover hidden patterns and improve the interpretability of incomplete datasets. This iterative approach ensures robust analysis even with partially labeled data.

This capability empowers users to iteratively refine AI model parameters, enhancing their ability to identify optimal setups for clustering and improving overall model interpretability and performance. In addition to the visual analytics approach, our framework incorporates quantified metrics through internal validation techniques to assess and characterize the clustering results produced by both the VAE and TFT models. These internal validation methods provide a complementary, data-driven evaluation of cluster quality, enhancing the robustness of the analysis. Details of these validation techniques are presented in Section 4.3.1.

# *4.3. Validation and Performance Comparison*

Through the case study, we utilize data from GSEL Data Provider 1 to showcase the validation process within our framework. This dataset is particularly well-suited for this purpose as it contains a rich diversity of class labels, enabling a comprehensive demonstration of the framework's ability to handle complex, multivariate time-series data and validate clustering performance of the TFT and VAE models effectively.

## *4.3.1. Internal Validation*

The validation process evaluates clustering results produced by TFT, VAE-1D CNN, and VAE-LSTM models under varying configurations of latent dimensions and dimensionality reduction algorithms (PCA, t-SNE, and UMAP) using internal validation metrics. These metrics assess cluster quality quantitatively, focusing on metrics like compactness, separation, and silhouette scores to characterize the effectiveness of the clustering. By comparing the clustering performance across different configurations, the process identifies optimal parameter combinations for generating well-separated and interpretable clusters, ensuring robust model evaluation and enabling users to fine-tune AI models for improved performance.

## *4.3.2. Human-in-the-loop Validation*

Using the use case presented in Section 4.2.1 as an example, the spatial proximity of the 2D latent representations for "Arching" and "Jumper Failure" can be effectively explained and interpreted through the lens of power grid management domain knowledge. In power grid operation and urban power system management, "Arching" and "Jumper Failure" are closely interrelated due to shared physical processes and operational dependencies. Jumper failures, which involve the breakdown or disconnection of flexible conductors, often create unstable circuits, resulting in abnormal voltage conditions that trigger arcing—electrical discharges across exposed or loose connections. Conversely, the intense heat generated by arcing can degrade insulation and weaken nearby jumpers, leading to further failures. These events frequently co-occur in both temporal and spatial proximity, particularly at points of mechanical stress, aging infrastructure, or under transient conditions such as switching surges or lightning strikes. Environmental factors, such as thermal cycling, wind loads, and vibrations, exacerbate these failures, particularly in older urban systems. Understanding the dependency between these fault patterns enables grid operators to improve fault diagnosis, identify

![](_page_25_Figure_0.jpeg)

root causes, and implement predictive maintenance strategies, ultimately enhancing the resilience and reliability of power distribution systems.

Figure 5: Use case 3: comparing clustering results under different configuration parameters

The data-driven exploration of potential interconnections between the signal event patterns EA (Arching), OU (Jumper Failure), and other neighboring event patterns, such as IF (Interrupting Devices - Fuse), DE (Equipment Deterioration), and TN (Nonspecific Transformer Failure), can be also justified using power grid domain knowledge. Arching and jumper failures often serve as precursors or co-occurring events with other equipment-related issues. For instance, Interrupting Devices (IF), such as fuses, are designed to protect the system by isolating faults; their activation may be triggered by arcing or jumper disconnections. Similarly, Equipment Deterioration (DE) and Transformer Failures (TN) are commonly observed consequences of prolonged arcing and mechanical stress from jumper failures, which can accelerate insulation breakdown, thermal damage, and structural degradation. The proximity of these events in the latent space highlights shared underlying causes, such as aging infrastructure, mechanical wear, and transient voltage conditions, reinforcing the importance of identifying these interconnections for improved fault diagnosis and system resilience.

![](_page_26_Figure_1.jpeg)

Figure 6: Validating clustering results from TFT, VAE-1D CNN, and VAE-LSTM across different latent dimensions and dimensionality reduction algorithms (PCA, t-SNE, UMAP) using internal validation metrics.

# *4.3.3. Relative Validation*

Based on the methodology described in Section 3.6.3, we employed a correspondence plot to compare the latent representation clusters generated by the TFT and VAE models, as shown in Figure 7. The relative validation process evaluates the consistency and alignment of clustering results from these methods by utilizing KNN- and DBSCANbased cluster similarity metrics. These metrics quantitatively assess the proportion of identical neighbors within clusters, ensuring that only latent vectors with the same cluster labels are considered. For the dataset from Provider 1, applying the t-SNE dimensionality reduction method to latent vectors with a dimensionality of 640 yielded a cluster consistency score of 92.88% between TFT and VAE-1D CNN models and 93.56% between TFT and VAE-LSTM models.

In addition to these metrics, the correspondence plot provides a complementary visualization for comparing clustering results. This plot employs Dynamic Time Warping (DTW)-styled lines to connect latent vectors with the same ID across the two methods, offering an intuitive representation of the spatial distributions and structural alignments of clusters. The alignment and length of these lines highlight areas of agreement or divergence between the methods. Consistent clusters are visually distinct and well-aligned, while inconsistencies are localized and easily identifiable, as illustrated in the figure. By combining quantitative similarity metrics with visual analysis, this framework provides a comprehensive and robust approach for comparing and validating the clustering performance of TFT and VAE-based models, offering valuable insights into their reliability and robustness under different configurations. Although the demonstration in Figure 7 compares the clustering results of TFT and VAE-based models configured with a specific latent dimension and dimensionality reduction method, our methodology is versatile and can be applied to compare latent vector results across different models, latent dimensions, and dimensionality reduction techniques, such as PCA and UMAP. This flexibility enables broader exploratory analyses, allowing users to investigate various configurations and gain deeper insights into model performance and clustering behavior.

![](_page_27_Figure_3.jpeg)

Figure 7: Correspondence plot is developed to facilitate the comparison between the latent representation clusters produced from TFT and VAE models.

![](_page_28_Figure_1.jpeg)

![](_page_28_Figure_2.jpeg)

Figure 8: Model run-time comparison between TFT, VAE-1D CNN, and VAE-LSTM across different latent dimensions.

The Model Run-time Comparison evaluates the computational efficiency of TFT, VAE-1D CNN, and VAE-LSTM across varying latent dimensions, as shown in Figure "Model run-time comparison between TFT, VAE-1D CNN, and VAE-LSTM across different latent dimensions". The experiments were conducted on a computing device with the following specifications: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80 GHz (1.69 GHz) processor, 16 GB RAM, and a 64-bit operating system.

The runtime for all models increases with higher latent dimensions, with notable differences in scalability across the three approaches (illustrated in Figure 8). The TFT model demonstrates the fastest runtime, maintaining significantly lower computational costs across all latent dimensions. Even as the latent dimension increases to 800, the runtime remains under 100 seconds, highlighting its computational efficiency. In contrast, the VAE-1D CNN model shows a steady increase in runtime, starting from approximately 100 seconds at lower latent dimensions and reaching over 1000 seconds at higher dimensions. The VAE-LSTM model consistently exhibits the highest runtime, remaining above 1000 seconds across all latent dimensions, reflecting the additional computational overhead of processing sequential dependencies in LSTM-based architectures.

# *4.4.1. TFT E*ffi*ciency on Time-Series Data*

This comparison underscores the trade-offs between runtime performance and model architecture. While the TFT model offers the most efficient execution, making it ideal for large-scale datasets with short durations (due to its limited attention mechanism) and real-time applications, the VAE-1D CNN and VAE-LSTM models exhibit higher computational costs, particularly as latent dimensions increase. These findings provide valuable insights for users to balance runtime efficiency, model complexity, and task-specific requirements when selecting the appropriate model for their applications.

## *4.4.2. TFT Scalability and Adaptability*

An important observation from our study is that the TFT model demonstrates greater scalability and adaptability for analyzing multivariate time-series data with varying data shapes, such as differing numbers of features and changing time-series durations (data lengths). During our exploratory analysis of the GSEL data, we observed that datasets from different providers (vendors) often exhibit variations in the number of features, sampling rates, and temporal lengths. Unlike VAE-based models, which require significant modifications to the encoder architecture to accommodate data with varying shapes, the TFT model can handle such variations seamlessly without altering its core architecture. This flexibility makes TFT particularly well-suited for heterogeneous datasets, as it can adapt to different data structures while maintaining robust performance.

## *4.5. Limitation and Future Work*

The limitations of our work and their potential solutions include the following:

- Color-Coding Challenge for Multilabel Data Visualization : A significant challenge in visualizing multilabel data arises when using color-coding to represent categorical labels in a 2D space. For datasets with a large number of label combinations—potentially exceeding 100 unique combinations—there are not enough distinguishable colors available to adequately represent each combination. As the number of labels grows, it becomes increasingly difficult to assign unique, perceptually differentiable colors to each data point, leading to visual ambiguity, clutter, and reduced interpretability. This limitation complicates the analysis, as users may struggle to identify patterns, relationships, or clusters within the data. Future work could address this challenge by exploring alternative visualization strategies, such as glyph-based representations, where shape, size, or texture encodes additional label information, or interactive filtering techniques that allow users to focus on specific subsets of label combinations. Additionally, techniques like hierarchical grouping or dimensionality reduction of labels can help reduce visual complexity while maintaining meaningful insights.
- Long Time-Sequence Limitation : Our current TFT architecture is not optimized for analyzing time-series data with very long sequences, as the Transformer's attention mechanism can be computationally expensive and may struggle to capture long-range dependencies effectively. We conducted experiments using augmented time-series data from GESL Provider 1, which contains sequences of up to 20K time steps, and observed a noticeable decline in performance based on internal validation metrics. This highlights the limitations of the current TFT implementation for long-sequence modeling due to its quadratic complexity. Future work includes enhancing the TFT by integrating Temporal Convolutional Networks (TCNs) or Recurrent Neural Networks (RNNs), which are well-suited for long-sequence tasks, to improve efficiency and the model's ability to capture long-term temporal dependencies.
- Limitations of External Validation for Multilabel Data : A key limitation in validating the clustering results of our framework lies in the lack of solid ground truth data for external validation. The dataset is inherently multilabel, where each data point can have multiple class labels, resulting in a large number of unique label combinations. These combinations often imply potential dependencies and interconnections between multiple events, making it difficult to establish a clear, one-to-one mapping between predicted clusters and predefined labels. Standard external validation metrics, such as the F1 score, are designed for single-label classification tasks and do not adequately capture the complexities and interdependencies present in multilabel data. As a result, clustering results cannot be easily validated using traditional quantitative approaches. Instead, visual analytics and domain knowledge play a critical role in interpreting and justifying the clustering outputs, as they allow for the exploration of latent structures, co-occurring labels, and underlying event relationships. Moving forward, the development of domain-specific or hybrid validation techniques that combine quantitative metrics with visual interpretations may provide a more robust solution for assessing clustering performance in multilabel datasets.
- Visual Encoding Complexity : A notable limitation of our method lies in the complexity of its visual encodings, which require users to have domain-specific knowledge and invest time in exploring patterns through interactive techniques. While the Multivariate 2D Latent Vector Map and Hierarchical Multi-label Tree provide advanced tools for analyzing multivariate time-series data, their effective use depends heavily on the user's familiarity with the domain and understanding of the underlying data structures. This requirement may present a barrier to users who lack extensive domain expertise or are unfamiliar with visual analytics workflows. A potential improvement to address this challenge is the incorporation of Large Language Models (LLMs) as AI agents within the framework. These AI agents could serve as visual guides, dynamically explaining complex visual encodings and highlighting key patterns or insights to users. By integrating LLMs to facilitate user understanding and interaction, future iterations of the framework could significantly enhance accessibility, reduce the learning curve, and broaden its applicability to non-expert users.
- Limited Analysis on TFT and VAE Cluster Inconsistency : The current research introduces a relative validation method using correspondence plots and shape-matching metrics to compare the consistency of latent vector clusters generated by different generative AI models. However, the analysis stops short of a deeper investigation into the causes of cluster inconsistency. Future work could extend this comparative analysis into an ensemble-based approach that characterizes the event patterns contributing to the inconsistencies, focusing on their class labels and data quality. Such an approach could help identify the root causes of disagreements between TFT and VAE-based models, providing valuable insights into underlying data anomalies or model limitations. This deeper understanding would enhance AI explainability, allowing for more transparent and interpretable outcomes in multivariate time-series analysis.

Future work for this study includes the integration of more advanced generative AI technologies to address the current

framework's limitations. Specifically, knowledge-augmented large language models (LLMs) could be leveraged to enhance data acquisition, transformation, and pattern justification by utilizing specialized knowledge bases (Xu et al., 2024). This could be enabled through the Retrieval-Augmented Generation (RAG) paradigm, allowing LLMs to perform specialized tasks using domain-specific knowledge (Tupayachi et al., 2024). Additionally, the generative AI models already employed in the framework, namely the TFT and VAEs, could be further utilized to improve the quality of multivariate time-series data prior to their introduction into the framework for analysis. By refining input data and incorporating domain-driven insights through data augmentation and missing data imputation, these advancements could significantly enhance the framework's robustness and applicability.
