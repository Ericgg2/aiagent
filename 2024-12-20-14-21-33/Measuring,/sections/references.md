[1]Mark S Ackerman. 2000. The intellectual challenge of CSCW: the gap between social requirements and technical
feasibility. Human–Computer Interaction 15, 2-3 (2000), 179–203.
[2]Alessandro Acquisti, Idris Adjerid, Rebecca Balebako, Laura Brandimarte, Lorrie Faith Cranor, Saranga Komanduri,
Pedro Giovanni Leon, Norman Sadeh, Florian Schaub, Manya Sleeper, et al .2017. Nudges for privacy and security:
Understanding and assisting users’ choices online. ACM Computing Surveys (CSUR) 50, 3 (2017), 1–41.
[3]Drew Afualo. 2023. Help! I found my boyfriend’s reddit history. dear god. https://slate.com/human-interest/2023/02/
boyfriend-reddit-history-dear-prudence-advice.html
[4]Chandan Akiti, Anna Squicciarini, and Sarah Rajtmajer. 2020. A semantics-based approach to disclosure classification
in user-generated online content. In Findings of the Association for Computational Linguistics: EMNLP 2020 . 3490–3499.
[5]Tawfiq Ammari, Sarita Schoenebeck, and Daniel Romero. 2019. Self-declared throwaway accounts on Reddit:
How platform affordances and shared norms enable parenting disclosure and support. Proceedings of the ACM on
Human-Computer Interaction 3, CSCW (2019), 1–30.
[6]Dhananjay Ashok and Zachary C Lipton. 2023. PromptNER: Prompting For Named Entity Recognition. arXiv preprint
arXiv:2305.15444 (2023).
[7]Marieke Bak, Vince Istvan Madai, Marie-Christine Fritzsche, Michaela Th Mayrhofer, and Stuart McLennan. 2022.
You can’t have AI both ways: balancing health data privacy and access fairly. Frontiers in Genetics 13 (2022), 1490.
[8]Dina Bass and Ellen Huet. 2017. Researchers Combat Gender and Racial Bias in Artificial Intelligence . https://www.
bloomberg.com/news/articles/2017-12-04/researchers-combat-gender-and-racial-bias-in-artificial-intelligence
[9]Michael Bernstein, Andrés Monroy-Hernández, Drew Harry, Paul André, Katrina Panovich, and Greg Vargas. 2011.
4chan and/b: An Analysis of Anonymity and Ephemerality in a Large Online Community. In Proceedings of the
international AAAI conference on web and social media , Vol. 5. 50–57.
[10] Taylor Blose, Prasanna Umar, Anna Squicciarini, and Sarah Rajtmajer. 2020. Privacy in Crisis: A study of self-disclosure
during the Coronavirus pandemic. arXiv preprint arXiv:2004.09717 (2020).
[11] Laura Brandimarte, Alessandro Acquisti, and George Loewenstein. 2013. Misplaced confidences: Privacy and the
control paradox. Social psychological and personality science 4, 3 (2013), 340–347.
[12] Alex Braunstein, Laura Granka, and Jessica Staddon. 2011. Indirect content privacy surveys: measuring privacy
without asking about it. In Proceedings of the Seventh Symposium on Usable Privacy and Security . 1–14.
[13] Kelly Caine. 2016. Local standards for sample size at CHI. In Proceedings of the 2016 CHI conference on human factors
in computing systems . 981–992.
[14] Gerardo Canfora, Andrea Di Sorbo, Enrico Emanuele, Sara Forootani, and Corrado A Visaggio. 2018. A NLP-based
solution to prevent from privacy leaks in social network posts. In Proceedings of the 13th International Conference on
Availability, Reliability and Security . 1–6.
[15] Baiyun Chen and Justin Marcus. 2012. Students’ self-presentation on Facebook: An examination of personality and
self-construal factors. Computers in Human Behavior 28, 6 (2012), 2091–2099.
[16] Christy Cheung, Zach WY Lee, and Tommy KH Chan. 2015. Self-disclosure in social networking sites: the role of
perceived cost, perceived benefits and social influence. Internet Research 25, 2 (2015), 279–299.
[17] Won Ik Cho, Soomin Kim, Eujeong Choi, and Younghoon Jeong. 2022. Assessing How Users Display Self-Disclosure
and Authenticity in Conversation with Human-Like Agents: A Case Study of Luda Lee. In Findings of the Association
for Computational Linguistics: AACL-IJCNLP 2022 , Yulan He, Heng Ji, Sujian Li, Yang Liu, and Chua-Hui Chang (Eds.).
Association for Computational Linguistics, Online only, 145–152. https://aclanthology.org/2022.findings-aacl.14
23Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway Krsek, et al.
[18] Won Ik Cho, Soomin Kim, Eujeong Choi, and Younghoon Jeong. 2022. Assessing How Users Display Self-Disclosure
and Authenticity in Conversation with Human-Like Agents: A Case Study of Luda Lee. In Findings of the Association
for Computational Linguistics: AACL-IJCNLP 2022 . 145–152.
[19] Arijit Ghosh Chowdhury, Ramit Sawhney, Puneet Mathur, Debanjan Mahata, and Rajiv Ratn Shah. 2019. Speak up,
fight back! detection of social media disclosures of sexual harassment. In Proceedings of the 2019 conference of the
North American chapter of the Association for Computational Linguistics: Student research workshop . 136–146.
[20] Kate Crawford, Meredith Whittaker, Madeleine Clare Elish, Solon Barocas, Aaron Plasek, and Kadija Ferryman. 2016.
The AI now report. The Social and Economic Implications of Artificial Intelligence Technologies in the Near-Term 2
(2016).
[21] Bhavana Dalvi, Oyvind Tafjord, and Peter Clark. 2022. Towards teachable reasoning systems: Using a dynamic
memory of user feedback for continual system improvement. In Proceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing . 9465–9480.
[22] Sauvik Das and Adam Kramer. 2013. Self-censorship on Facebook. In Proceedings of the International AAAI Conference
on Web and Social Media , Vol. 7. 120–127.
[23] Sauvik Das, Hao-Ping Lee, and Jodi Forlizzi. 2023. Privacy in the Age of AI. Commun. ACM 66, 11 (2023), 29–31.
[24] Munmun De Choudhury and Sushovan De. 2014. Mental health discourse on reddit: Self-disclosure, social support,
and anonymity. In Proceedings of the international AAAI conference on web and social media , Vol. 8. 71–80.
[25] Joost CF De Winter and Dimitra Dodou. 2010. Five-point Likert items: t test versus Mann-Whitney-Wilcoxon. Practical
assessment, research & evaluation 15 (2010), 1–12.
[26] Judith Donath. 1999. S.(1999). Identity and deception in the virtual community. Communities in cyberspace (1999),
29–59.
[27] Yao Dou, Isadora Krsek, Tarek Naous, Anubha Kabra, Sauvik Das, Alan Ritter, and Wei Xu. 2023. Reducing Privacy
Risks in Online Self-Disclosures with Language Models. arXiv preprint arXiv:2311.09538 (2023).
[28] Bushra Ebadi. 2018. Artificial Intelligence Could Magnify Social Inequality . https://www.cigionline.org/articles/
artificial-intelligence-could-magnify-social-inequality/
[29] Malik ERGİN and Ozgur KOSKAN. 2023. Comparison of Student–t, Welch’st, and Mann–Whitney U Tests in Terms
of Type I Error Rate and Test Power. Selcuk Journal of Agriculture and Food Sciences 37, 2 (2023), 223–231.
[30] Cori Faklaris, Laura Dabbish, and Jason I Hong. 2022. Do They Accept or Resist Cybersecurity Measures? Development
and Validation of the 13-Item Security Attitude Inventory (SA-13). arXiv preprint arXiv:2204.03114 (2022).
[31] Joseph L Fleiss, Bruce Levin, and Myunghee Cho Paik. 2013. Statistical methods for rates and proportions . john wiley
& sons.
[32] Jill J Francis, Marie Johnston, Clare Robertson, Liz Glidewell, Vikki Entwistle, Martin P Eccles, and Jeremy M
Grimshaw. 2010. What is an adequate sample size? Operationalising data saturation for theory-based interview
studies. Psychology and health 25, 10 (2010), 1229–1245.
[33] Kevin Gallagher, Sameer Patil, and Nasir Memon. 2017. New Me: Understanding Expert and {Non-Expert}Perceptions
and Usage of the Tor Anonymity Network. In Thirteenth Symposium on Usable Privacy and Security (SOUPS 2017) .
385–398.
[34] Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. 2023. Chatgpt outperforms crowd-workers for text-annotation
tasks. arXiv preprint arXiv:2303.15056 (2023).
[35] Thomas Gries and Wim Naudé. 2022. Modelling artificial intelligence in economics. Journal for labour market research
56, 1 (2022), 12.
[36] Ralph Gross and Alessandro Acquisti. 2005. Information revelation and privacy in online social networks. In
Proceedings of the 2005 ACM workshop on Privacy in the electronic society . 71–80.
[37] Alfonso Guarino, Delfina Malandrino, and Rocco Zaccagnino. 2022. An automatic mechanism to provide privacy
awareness and control over unwittingly dissemination of online private information. Computer Networks 202 (2022),
108614.
[38] Greg Guest, Arwen Bunce, and Laura Johnson. 2006. How many interviews are enough? An experiment with data
saturation and variability. Field methods 18, 1 (2006), 59–82.
[39] Greg Guest, Emily Namey, and Mario Chen. 2020. A simple method to assess and report thematic saturation in
qualitative research. PloS one 15, 5 (2020), e0232076.
[40] Ashley K Hagaman and Amber Wutich. 2017. How many interviews are enough to identify metathemes in multisited
and cross-cultural research? Another perspective on Guest, Bunce, and Johnson’s (2006) landmark study. Field
methods 29, 1 (2017), 23–41.
[41] Mariea Grubbs Hoy and George Milne. 2010. Gender differences in privacy-related measures for young adult Facebook
users. Journal of interactive advertising 10, 2 (2010), 28–45.
[42] Hilary Hutchinson, Wendy Mackay, Bo Westerlund, Benjamin B Bederson, Allison Druin, Catherine Plaisant, Michel
Beaudouin-Lafon, Stéphane Conversy, Helen Evans, Heiko Hansen, et al .2003. Technology probes: inspiring design
24... Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway
for and with families. In Proceedings of the SIGCHI conference on Human factors in computing systems . 17–24.
[43] Jun Li Jeung and Janet Yi-Ching Huang. 2023. Correct Me If I Am Wrong: Exploring How AI Outputs Affect User
Perception and Trust. In Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and
Social Computing . 323–327.
[44] Adam N Joinson. 2001. Self-disclosure in computer-mediated communication: The role of self-awareness and visual
anonymity. European journal of social psychology 31, 2 (2001), 177–192.
[45] Cameron F Kerry. 2020. Protecting privacy in an AI-driven world. (2020).
[46] Anton Khritankov. 2023. Positive feedback loops lead to concept drift in machine learning systems. Applied Intelligence
53, 19 (2023), 22648–22666.
[47] Hanna Krasnova, Sarah Spiekermann, Ksenia Koroleva, and Thomas Hildebrand. 2010. Online social networks: Why
we disclose. Journal of information technology 25, 2 (2010), 109–125.
[48] J Richard Landis and Gary G Koch. 1977. The measurement of observer agreement for categorical data. biometrics
(1977), 159–174.
[49] Noam Lapidot-Lefler and Azy Barak. 2015. The benign online disinhibition effect: Could situational factors induce
self-disclosure and prosocial behaviors? Cyberpsychology: Journal of Psychosocial Research on Cyberspace 9, 2 (2015).
[50] Alex Leavitt. 2015. " This is a Throwaway Account" Temporary Technical Identities and Perceptions of Anonymity in
a Massive Online Community. In Proceedings of the 18th ACM conference on computer supported cooperative work &
social computing . 317–327.
[51] Hao-Ping Lee, Yu-Ju Yang, Thomas Serban von Davier, Jodi Forlizzi, and Sauvik Das. 2023. Deepfakes, Phrenology,
Surveillance, and More! A Taxonomy of AI Privacy Risks. arXiv preprint arXiv:2310.07879 (2023).
[52] Jooyoung Lee, Sarah Rajtmajer, Eesha Srivatsavaya, and Shomir Wilson. 2023. Online Self-Disclosure, Social Support,
and User Engagement During the COVID-19 Pandemic. ACM Transactions on Social Computing (2023).
[53] Jacob Liedke and Luxuan Wang. 2023. Social Media and News Fact sheet. https://www.pewresearch.org/journalism/
fact-sheet/social-media-and-news-fact-sheet/
[54] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer,
and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692
(2019).
[55] Grigorios Loukides, Joshua C Denny, and Bradley Malin. 2010. The disclosure of diagnosis codes can breach research
participants’ privacy. Journal of the American Medical Informatics Association 17, 3 (2010), 322–327.
[56] M Granger Morgan. 2002. Risk communication: A mental models approach . Cambridge University Press.
[57] John X Morris, Justin T Chiu, Ramin Zabih, and Alexander M Rush. 2022. Unsupervised Text Deidentification. arXiv
preprint arXiv:2210.11528 (2022).
[58] Blake Murdoch. 2021. Privacy and artificial intelligence: challenges for protecting health information in a new era.
BMC Medical Ethics 22, 1 (2021), 1–5.
[59] Kanchan Naithani and Shrikant Tiwari. 2024. Deep Learning for the Intersection of Ethics and Privacy in Healthcare.
InMachine Learning Algorithms Using Scikit and TensorFlow Environments . IGI Global, 154–191.
[60] Emily Namey, Greg Guest, Kevin McKenna, and Mario Chen. 2016. Evaluating bang for the buck: a cost-effectiveness
comparison between individual interviews and focus groups based on thematic saturation levels. American Journal of
Evaluation 37, 3 (2016), 425–440.
[61] OpenAI. 2023. GPT-4 Technical Report. ArXiv abs/2303.08774 (2023). https://api.semanticscholar.org/CorpusID:
257532815
[62] Sunghyun Park, Han Li, Ameen Patel, Sidharth Mudgal, Sungjin Lee, Young-Bum Kim, Spyros Matsoukas, and
Ruhi Sarikaya. 2020. A scalable framework for learning from implicit user feedback to improve natural language
understanding in large-scale conversational AI systems. arXiv preprint arXiv:2010.12251 (2020).
[63] Eyal Peer, Laura Brandimarte, Sonam Samat, and Alessandro Acquisti. 2017. Beyond the Turk: Alternative platforms
for crowdsourcing behavioral research. Journal of experimental social psychology 70 (2017), 153–163.
[64] James W Pennebaker and Cindy K Chung. 2007. Expressive writing, emotional upheavals, and health. Foundations of
health psychology (2007), 263–284.
[65] Strategic Plan. 2016. The national artificial intelligence research and development strategic plan. National Science and
Technology Council, Networking and Information Technology Research and Development Subcommittee (2016).
[66] Kevin Proudfoot. 2023. Inductive/Deductive hybrid thematic analysis in mixed methods research. Journal of Mixed
Methods Research 17, 3 (2023), 308–326.
[67] Charles Pulliam-Moore. 2021. Simu Liu’s alleged old reddit account is why you should never post. https://gizmodo.
com/simu-lius-alleged-old-reddit-account-is-why-you-should-1847708695
[68] Catharine H Rankin, Thomas Abrams, Robert J Barry, Seema Bhatnagar, David F Clayton, John Colombo, Gianluca
Coppola, Mark A Geyer, David L Glanzman, Stephen Marsland, et al .2009. Habituation revisited: an updated and
revised description of the behavioral characteristics of habituation. Neurobiology of learning and memory 92, 2 (2009),
25Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway Krsek, et al.
135–138.
[69] Shailendra Rathore, Pradip Kumar Sharma, Vincenzo Loia, Young-Sik Jeong, and Jong Hyuk Park. 2017. Social
network security: Issues, challenges, threats, and solutions. Information sciences 421 (2017), 43–69.
[70] Rachael A Record, Will R Silberman, Joshua E Santiago, and Taewook Ham. 2018. I sought it, I Reddit: Examining
health information engagement behaviors among Reddit users. Journal of health communication 23, 5 (2018), 470–476.
[71] Elissa M Redmiles, Sean Kross, and Michelle L Mazurek. 2019. How well do my results generalize? comparing security
and privacy survey results from mturk, web, and telephone samples. In 2019 IEEE Symposium on Security and Privacy
(SP). IEEE, 1326–1343.
[72] Elissa M Redmiles, Amelia R Malone, and Michelle L Mazurek. 2016. I think they’re trying to tell me something:
Advice sources and selection for digital security. In 2016 IEEE Symposium on Security and Privacy (SP) . IEEE, 272–288.
[73] Ann-Katrin Reuel, Sebastian Peralta, João Sedoc, Garrick Sherman, and Lyle Ungar. 2022. Measuring the language of
self-disclosure across corpora. In Findings of the Association for Computational Linguistics: ACL 2022 . 1035–1047.
[74] Luc Rocher, Julien M Hendrickx, and Yves-Alexandre De Montjoye. 2019. Estimating the success of re-identifications
in incomplete datasets using generative models. Nature communications 10, 1 (2019), 1–9.
[75] Bryan Semaan, Lauren M Britton, and Bryan Dosono. 2017. Military masculinity and the travails of transitioning:
Disclosure in social media. In Proceedings of the 2017 ACM Conference on computer supported cooperative work and
social computing . 387–403.
[76] Manya Sleeper. 2016. Everyday online sharing . Ph. D. Dissertation. Carnegie Mellon University.
[77] Manya Sleeper, Rebecca Balebako, Sauvik Das, Amber Lynn McConahy, Jason Wiese, and Lorrie Faith Cranor. 2013.
The post that wasn’t: exploring self-censorship on facebook. In Proceedings of the 2013 conference on Computer
supported cooperative work . 793–802.
[78] Alison Smith-Renner, Ron Fan, Melissa Birchfield, Tongshuang Wu, Jordan Boyd-Graber, Daniel S Weld, and Leah
Findlater. 2020. No explainability without accountability: An empirical study of explanations and feedback in
interactive ml. In Proceedings of the 2020 chi conference on human factors in computing systems . 1–13.
[79] Robin Staab, Mark Vero, Mislav Balunović, and Martin Vechev. 2023. Beyond Memorization: Violating Privacy Via
Inference with Large Language Models. arXiv preprint arXiv:2310.07298 (2023).
[80] Jaimee Stuart and Riley Scott. 2021. The Measure of Online Disinhibition (MOD): Assessing perceptions of reductions
in restraint in the online environment. Computers in Human Behavior 114 (2021), 106534.
[81] Evdoxia Taka, Yuri Nakao, Ryosuke Sonoda, Takuya Yokota, Lin Luo, and Simone Stumpf. 2023. Exploring the Impact
of Lay User Feedback for Improving AI Fairness. arXiv preprint arXiv:2312.08064 (2023).
[82] David G Taylor, Donna F Davis, and Ravi Jillapalli. 2009. Privacy concern and online personalization: The moderating
effects of information control and compensation. Electronic commerce research 9 (2009), 203–223.
[83] Erik F. Tjong Kim Sang and Jorn Veenstra. 1999. Representing Text Chunks. In Ninth Conference of the European
Chapter of the Association for Computational Linguistics , Henry S. Thompson and Alex Lascarides (Eds.). Association
for Computational Linguistics, Bergen, Norway, 173–179. https://aclanthology.org/E99-1023
[84] Manuel Tonneau, Dhaval Adjodah, Joao Palotti, Nir Grinberg, and Samuel Fraiberger. 2022. Multilingual Detection of
Personal Employment Status on Twitter. In Proceedings of the 60th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) . 6564–6587.
[85] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov,
Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al .2023. Llama 2: Open foundation and fine-tuned chat models.
arXiv preprint arXiv:2307.09288 (2023).
[86] Prasanna Umar, Anna Cinzia Squicciarini, and Sarah Michele Rajtmajer. 2019. Detection and Analysis of Self-Disclosure
in Online News Commentaries. The World Wide Web Conference (2019). https://api.semanticscholar.org/CorpusID:
86467407
[87] Mina Valizadeh, Xing Qian, Pardis Ranjbar-Noiey, Cornelia Caragea, and Natalie Parde. 2023. What Clued the AI
Doctor In? On the Influence of Data Source and Quality for Transformer-Based Medical Self-Disclosure Detection. In
Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics . 1193–1208.
[88] Mina Valizadeh, Pardis Ranjbar-Noiey, Cornelia Caragea, and Natalie Parde. 2021. Identifying Medical Self-Disclosure
in Online Communities. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Com-
putational Linguistics: Human Language Technologies , Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek
Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (Eds.). Association
for Computational Linguistics, Online, 4398–4408. https://doi.org/10.18653/v1/2021.naacl-main.347
[89] Mina Valizadeh, Pardis Ranjbar-Noiey, Cornelia Caragea, and Natalie Parde. 2021. Identifying medical self-disclosure
in online communities. In Proceedings of the 2021 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies . 4398–4408.
[90] Anthony J Viera, Joanne M Garrett, et al .2005. Understanding interobserver agreement: the kappa statistic. Fam med
37, 5 (2005), 360–363.
26... Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway
[91] Nazar Waheed, Muhammad Ikram, Saad Sajid Hashmi, Xiangjian He, and Priyadarsi Nanda. 2022. An empirical
assessment of security and privacy risks of web-based chatbots. In International Conference on Web Information
Systems Engineering . Springer, 325–339.
[92] Yang Wang, Pedro Giovanni Leon, Alessandro Acquisti, Lorrie Faith Cranor, Alain Forget, and Norman Sadeh. 2014.
A field trial of privacy nudges for facebook. In Proceedings of the SIGCHI conference on human factors in computing
systems . 2367–2376.
[93] Yang Wang, Gregory Norcie, Saranga Komanduri, Alessandro Acquisti, Pedro Giovanni Leon, and Lorrie Faith Cranor.
2011. " I regretted the minute I pressed share" a qualitative study of regrets on Facebook. In Proceedings of the seventh
symposium on usable privacy and security . 1–16.
[94] Rachel Wicks and Matt Post. 2021. A unified approach to sentence segmentation of punctuated text in many languages.
InProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing (Volume 1: Long Papers) , Chengqing Zong, Fei Xia, Wenjie Li, and Roberto
Navigli (Eds.). Association for Computational Linguistics, Online, 3995–4007. https://doi.org/10.18653/v1/2021.acl-
long.309
[95] Justin Wu and Daniel Zappala. 2018. When is a tree really a truck? exploring mental models of encryption. In
Fourteenth Symposium on Usable Privacy and Security (SOUPS 2018) . 395–409.
[96] Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, and Yuji Matsumoto. 2020. Luke: deep contextualized
entity representations with entity-aware self-attention. arXiv preprint arXiv:2010.01057 (2020).
[97] Diyi Yang, Zheng Yao, and Robert Kraut. 2017. Self-disclosure and channel difference in online health support groups.
InProceedings of the international AAAI conference on web and social media , Vol. 11. 704–707.
[98] Diyi Yang, Zheng Yao, Joseph Seering, and Robert Kraut. 2019. The channel matters: Self-disclosure, reciprocity
and social support in online cancer support groups. In Proceedings of the 2019 chi conference on human factors in
computing systems . 1–15.
[99] Haejin Yun. 2006. The creation and validation of a perceived anonymity scale based on the social information processing
model and its nomological network test in an online social support community . Michigan State University.
[100] Eric Zeng, Shrirang Mare, and Franziska Roesner. 2017. End user security and privacy concerns with smart homes. In
thirteenth symposium on usable privacy and security (SOUPS 2017) . 65–80.
[101] Xing Zhang, Shan Liu, Xing Chen, Lin Wang, Baojun Gao, and Qing Zhu. 2018. Health information privacy concerns,
antecedents, and information disclosure intention in online health communities. Information & Management 55, 4
(2018), 482–493.
[102] Xinyan Zhao, Deahan Yu, and VG Vinod Vydiswaran. 2019. Identifying adverse drug events mentions in tweets using
attentive, collocated, and aggregated medical representation. In Proceedings of the Fourth Social Media Mining for
Health Applications (# SMM4H) Workshop & Shared Task . 62–70.
[103] Verena Zimmermann and Karen Renaud. 2021. The nudge puzzle: matching nudge interventions to cybersecurity
decisions. ACM Transactions on Computer-Human Interaction (TOCHI) 28, 1 (2021), 1–45.
[104] Shi Zong, Alan Ritter, Graham Mueller, and Evan Wright. 2019. Analyzing the perceived severity of cybersecurity
threats reported on social media. arXiv preprint arXiv:1902.10680 (2019).
27Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway Krsek, et al.
A APPENDICES
A.1 Table A: Demographics
DEMOGRAPHIC SUMMARY STRATIFIED BY GENDER
Female Male Non-binary Total (N=21)
Age18-29 3 (25.0) 3 (42.9) 2 (100.0) 8
30-49 6 (50.0) 2 (28.6) 0 8
50-64 2 (16.7) 1 (14.3) 0 3
65 years and older 1 (8.3) 1 (14.3) 0 2
EducationGraduate degree 1 (8.3) 3 (42.9) 1 (50.0) 9
Bachelor’s degree 3 (25.0) 3 (42.9) 0 6
Some college 7 (58.3) 1 (14.3) 0 8
High school degree 1 (8.3) 0 0 1
Employment StatusFull-time 1 (8.3) 3 (42.9) 0 4
Part-time 5 (41.7) 1 (14.3) 1 (50.0) 7
Unemployed & looking 2 (16.7) 1 (14.3) 1 (50.0) 4
Unemployed & not looking 3 (25.0) 2 (28.6) 0 5
Self-employed 1 (8.3) 0 0 5
Income$100k+ 0 2 (28.6) 0 2
$75k-99k 1 (8.3) 2 (28.6) 0 3
$50k-74k 2 (16.7) 2 (28.6) 1 (50.0) 5
$25k-49k 3 (25.0) 1(14.3) 0 4
<$25k 6 (50.0) 0 1 (50.0) 7
EthnicityBlack/African 2(16.7) 1(14.3) 0 3
Caucasian 10 (83.3) 4 (57.1) 2 (100.0) 16
South Asian 0 2 (28.6) 0 2
LocationLarge city 7 (58.3) 2(28.6) 1 (50.0) 10
Suburb near large city 3 (25.0) 4 (57.1) 1 (50.0) 8
Small city or town 1 (8.3) 1 (14.3) 0 2
Rural area 1 (8.3) 0 0 1
28... Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway
A.2 Table B: User Alteration Decisions
SUMMARY OF USER REACTIONS TO ACCEPTED VS. REJECTED DISCLOSURE SPANS
Accepted Spans (495) Rejected Spans (356) Total (851)
**Altered 23% (114) 3.7% (13)
Undecided 5% (23) 2% (7) 3% (30)
Don’t Alter 72% (357) 94.1% (335) 81% (692)
Table 4. The rate of different reactions participants had to the disclosure detection spans, compared between
disclosure spans that participants agreed contained self-disclosure (accepted spans), and spans participants
felt did not contain self-disclosure (rejected spans).
*The altered rate is a sum of changed spans and removed disclosure spans.
A.3 Table C: Categorical Disclosure Model Disclosure Span Acceptance/Rejection by
Category
SUMMARY OF USER REACTIONS & DETECTION ISSUES ACROSS DIFFERENT CATEGORIES OF MULTI-
CLASS MODEL
Category
(By most populous)Rejection
RateAcceptance
RateCountDidn’t
Make SenseMissing
ContextUser Preference
MisalignmentIncorrect
TagMultiple
TagsOther
(under/over highlighted)
Family 35% 65% 158 28 (18%) 8 (5%) 14 (9%) 35 (22%) 1 (1%) 7 (4%)
Husband/BF 43% 57% 81 7 (9%) 2 (2%) 21 (26%) 13 (16%) 0 2 (2%)
Health 31% 69% 58 12 (21%) 3 (5%) 3 (5%) 6 (5%) 0 0
Mental Health 27.5% 72.5% 40 8 (20%) 0 2 (5%) 6 (15%) 0 2 (5%)
Location 24% 76% 34 1 (3%) 0 5 (15%) 1 (29%) 0 0
Relationship Status 38% 62% 34 3 (9%) 0 4 (12%) 3 (9%) 0 1 (2%)
Pet 28% 72% 32 0 1 (3%) 5 (16%) 5 (6%) 0 3 (9%)
Finance 46% 54% 24 4 (17%) 1 (4%) 4 (17%) 1 (4%) 0 0
Age 38% 62% 21 2 (9%) 2 (10%) 3 (14%) 1 (5%) 0 0
Occupation 45% 55% 20 1 (5%) 1 (5%) 5 (25%) 5 (25%) 0 2 (10%)
Age/Gender 12.5% 87.5% 16 0 0 3 (19%) 0 0 0
Gender 30% 70% 10 2 (20%) 2 (20%) 0 3 (30%) 0 0
Sexual Orientation 50% 50% 10 3 (30%) 0 1 (10%) 4 (40%) 0 0
Education 25% 75% 8 0 0 2 (25%) 0 1 (13%) 0
Appearance 57% 43% 7 0 0 1 (14%) 1 (14%) 0 0
Race/Nationality 0% 100% 4 0 0 0 1 (25%) 0 0
Wife/GF 100% 0% 4 2 (50%) 0 2 (50%) 0 0 0
Total: 73 20 75 69 2 17
Table 5. The rate of acceptance and rejection across different categories of disclosure detected in the multi-
class model, alongside rates of model detection issues.
Note: This table only displays statistics for the multi-class model. "Name" and "Contact Information" do not
appear in this table since they did not appear in any post detections.
29Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway Krsek, et al.
A.4 Figure 4: Likert Scale Wording for Disclosure Detection Rankings
How would you rate the helpfulness of this highlight in surfacing a self-disclosure risk?
(1) Not at all helpful
(2) Somewhat helpful
(3) helpful
(4) Fairly helpful
(5) Very helpful
How important was it to disclose that information highlighted in your post?
(1) Not at all important
(2) Somewhat important
(3) Important
(4) Fairly important
(5) Very important
How would you rate the sensitivity of the content highlighted?
(1) Not at all sensitive
(2) Somewhat sensitive
(3) Sensitive
(4) Fairly sensitive
(5) Very sensitive
How risky do you feel it is to disclose the information highlighted in an online post?
(1) Not at all risky
(2) Somewhat risky
(3) Risky
(4) Fairly risky
(5) Very risky
Table 6. "Helpfulness", "importance", "sensitivity", and "riskiness" all ranked on a 5-point Likert Scale."
30... Accepted for publication at CSCW ’25, October 18 — 22, 2025, Bergen, Norway
A.5 Figure 5: Results of the Mann-Whitney U Test Alongside Welch’s T-test
SUMMARY STATISTICS FOR ACCEPTED SELF-DISCLOSURE SPANS OUTPUT BY THE MODELS
Accepted Altered Disclosure Spans
(114)Accepted Non-Altered Disclosure Spans
(357)Welch’s T-Test Results Mann-Whitney U Results
M SD M SD p-value Cohen’s dp-value
Helpfulness 4.14 1.24 3.15 1.44 1.52702e-10*** 0.24 1.489305e-09***
Importance 2.58 1.53 3.74 1.25 7.728284e-11*** 0.45 3.971501e-12***
Sensitivity 3.95 1.36 2.62 1.39 1.884628e-15*** 0.52 1.85884e-14***
Riskiness 3.61 1.47 2.22 1.35 8.741327e-15*** 0.52 4.353914e-15***
Table 7. Results of both the Mann-Whitney U test and Welch’s T-test for disclosure spans accepted by
participants to explain nuances in when participants altered and did not alter their posts in response to seeing
the model outputs. The outcomes of the two tests are in agreement, showing significant differences in the
mean and median scores of disclosure spans between those accepted and altered compared to those accepted
but not altered by participants across helpfulness, importance, sensitivity, and riskiness.
M = Mean, SD = Standard Deviation
Helpfulness, Importance, Sensitivity, and Riskiness all range from 1 (“Not at all...”) to 5 (“Very...”)
Note: p-values for both the Welch’s t-test and the Mann-Whitney U test have been adjusted for multiple
hypothesis testing.
*p<0.05, ** p<0.01, *** p<0.001
Received 16 January 2024; revised 16 July 2024; accepted 9 December 2024
31