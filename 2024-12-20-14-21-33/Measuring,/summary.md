## RELATED_WORK

## 1. 관련된 연구 범주

- **현재의 자아 노출의 이점과 위험 간의 균형 문제**: 
  - Reddit와 같은 온라인 가명 커뮤니티는 사용자에게 익명성 있는 공간을 제공.
  - 정보적 또는 정서적 지원을 위해 많은 개인적인 세부정보를 공개하는 경향이 있음.
  - 자아 노출은 연대감과 공동체 의식을 확립하는데 중요한 요소.
  - 부정적인 경험을 노출함으로써 지원감과 자신감이 증대될 수 있음.

- **자아 노출의 위험**: 
  - 자아 노출이 디지털 흔적을 남겨 재식별, 스토킹 등의 위험이 존재.
  - "쓰레기 계정"이나 "버너 계정" 사용으로 리스크를 줄이려 하지만 충분한 정보를 공개함.

- **리스크 인식**: 
  - 사용자는 공개하는 정보의 민감도와 리스크를 인식함.
  - 익명의 경우 사용자들은 더 자유롭고 솔직하게 표현할 수 있지만, 익명의 안전함은 자아 노출을 증가시킬 수 있음.

## 2. 자아 노출의 위험을 완화하기 위한 과거 접근법

- **비 AI 기반 도구**: 
  - 사용자의 자아 노출 위험을 탐색하는 다양한 방법이 연구됨.
  - 맞춤형 개인정보 보호 설정은 소셜 네트워크에서 유용하지만 자아 노출의 위험은 줄이지 못함.

- **AI 기반 도구**: 
  - 최근 NLP 기반 개입 도구가 개인정보 유출 방지를 위한 도구로 등장.
  - 개인적인 정보 노출을 명확히 식별하여 사용자에게 개선 사항을 제시.

## 3. AI 기술 설계에서 사용자 참여의 필요성

- AI 기술은 사회적 및 경제적 영향을 광범위하게 미침.
- AI 시스템의 배치에서 영향을 받는 사람들이 실질적으로 참여해야 함.
- 사용자 의견 수렴을 통해 AI 시스템 개발 및 정책 프레임워크에 반영할 수 있어야 함.
- 사용자 피드백을 반영하면 윤리적이고 책임감 있는 AI 개발을 촉진할 수 있음.

## 4. 자아 노출 탐지 모델

- 자아 노출 탐지 관련 이전 연구들은 문장 또는 게시물 수준의 분류에 집중.
- Dou et al.의 최신 모델은 17개의 고유한 범주를 단어 수준에서 탐지할 수 있음.
- 성능이 높고, 고유한 데이터를 활용하여 사용자 경험에 미치는 영향을 연구.

### Table 1: 각 자아 노출 범주에 대한 예시
범주 | 예시
-----|-----
Demographic Attributes | Age: I recently celebrated my 30th birthday.
| Gender: I am a guy and was shamed for doing ballet.
| ... | ...
Personal Experiences | Family: My brother fought my husband at a family dinner.
| Health: I’ve diagnosed with prostate cancer.
| ... | ...

이 연구는 AI를 통해 사용자가 개인정보를 공유하는 것에 대해 더 많은 정보를 바탕으로 결정할 수 있도록 지원하는 방향으로 진행됨.

---

## METHODOLOGY

## 연구 목적
- AI 지원 자가 노출 범위 식별이 사용자에게 자가 노출 위험 인식과 작성 행동에 미치는 영향을 탐구하기 위해 21명의 Reddit 사용자와 75분 간의 인터뷰 연구를 수행하였습니다.
- 연구 질문:
  - RQ1: 모델이 사용자 자가 노출 위험 인식에 미치는 영향
  - RQ2: 모델 피드백의 최대 유용성을 위한 프레이밍 방법
  - RQ3: 사용자의 선호를 더 잘 반영하기 위한 도구 수정 방법

## 4.1 모집
- 총 21명의 Reddit 사용자를 Prolific를 통해 모집하였습니다.
- 참가자는 다음 조건을 충족해야 했습니다:
  - 연구 시점에 Reddit 계정 보유
  - Reddit에 최소 3회 게시물 작성
  - 미국 거주 및 18세 이상
- 프라이버시 우려가 있는 게시물과 없는 게시물을 각각 1개씩 제출하도록 요청하였습니다.
- 최종적으로 158명 중 33명이 인터뷰 초대에 응답하였고, 그 중 21명이 인터뷰에 참여하였습니다.

**표 A**: 모은 인구 통계 데이터 (부록)
- 샘플은 약간 여성 쪽으로 치우쳤으며, 21명 중 12명이 여성이라고 밝혔습니다.

## 4.2 사전 연구 설문
- 참가자들은 자격 확인을 위한 온라인 설문조사에 응답하였고, 동의서를 제공하였습니다.
- 각 참가자는 프라이버시 우려가 있는 Reddit 게시물과 없는 게시물 링크를 공유하였습니다.
- 최종 부분에서는 Reddit 사용 및 행동, 자가 익명성 인식, 정보 공개 성향 등을 질의하였습니다.

## 4.3 인터뷰
- **모델 출력 평가**: 참가자들에게 각자의 게시물에 대해 모델의 출력에 대한 피드백을 수집하였습니다.
  - 인터뷰는 Reddit 사용 및 노출 기준에 대한 일반적인 질문으로 시작하였습니다.
  - 이후 참가자들에게 두 게시물의 출력에 대한 평가를 받았습니다.
- 참가자들은 모델 출력에 대한 평가와 5점 척도를 사용하여 도움, 중요성, 민감성, 위험성 등을 평가하였습니다.

## 4.4 데이터 분석
- **주제 분석**: 인터뷰 내용을 코드화하기 위해 귀납적 주제 분석 방법을 사용하였습니다.
- 두 연구자는 5개의 트랜스크립트를 검토하여 40개의 코드를 포함하는 코드북을 개발하였습니다.
- 박사급 연구원 두 명은 독립적으로 23%의 데이터 세트를 코드화하여 높은 일치율의 Cohen's Kappa (0.98)를 달성하였습니다.
- 참가자 반응과 모델 출력의 차이를 분석하여 민감한 자가노출이 포함된 것으로 비율, 반응 이유, 게시물 수정 여부를 비교하였습니다.

## KEYWORDS
- AI, self-disclosure, NLP, Reddit, privacy, user assessment, thematic analysis, Cohen's Kappa, survey, qualitative research, semi-structured interviews, statistical comparisons, Likert scale.

---

## DISCUSSION

### 주요 발견 요약 
- AI 보조 자기 공개 탐지 도구의 사용은 유망함과 위험을 동시에 내포하고 있음.
- 기존 연구는 효과적인 자기 공개 분류 모델 개발의 기술적 과제에 주목했으나, 본 연구는 이 문제가 본질적으로 사회-기술적이며 Ackerman의 사회-기술 격차를 나타내고 있음을 보여줌.
- 효과적인 해결책은 높은 F1 점수를 넘어서, 사용자의 위협 모델, 게시 맥락, 위험 완화 전략 및 위험 이해 등의 면을 고려해야 함.
  
### 연구 결과 요약 
- 대다수 참가자들은 모델, 특히 범주적 공개 변형에 긍정적인 반응을 보이며, 자기 반성을 촉진하고 사용자 오류를 포착하는 유용성을 평가함.
- 사용자는 공유를 고민하고 있는 콘텐츠에 대해 결정하는 데 도움이 될 것이라고 기대함.
- 참가자들은 범주적 공개 모델에서 제공하는 대략적인 설명을 높이 평가함. 이는 모델이 탐지한 공개의 “카테고리”를 통해 사용자 위험 인식의 차이를 인정할 수 있도록 도와줌.
  
### 향후 모델링 및 디자인 작업의 방향 
- 모델이 탐지할 수 있는 새로운 공개 카테고리의 필요성, 사실 및 비사실 공개 구분 필요성, 사용자 공개 이력 고려 필요성, 의미를 보존하면서 위험을 줄이는 방법이 필요함.
- 디자인 작업에서는 효과적인 설명 설계, 게시 맥락 및 공개 규범 고려, 사용자에게 중요한 공개를 우선하도록 하는 필요성이 강조됨.

### 실용적 함의 
- 연구는 AI 보조 자기 공개 탐지 도구의 적용 가능성을 여러 맥락에서 보여줌.
- 이 도구는 개별 소셜 미디어 사이트에서 사용될 수 있는 독립적인 도구로 유용하며, 플랫폼 설계에 통합될 수도 있음.
- 특정 상황에서 사용자 지원을 탐색하는 데 특히 유용함.

### 자가 공개 탐지 도구의 자연어 지침과 피드백에 대한 응답 
- 참가자들은 모델 출력에서 다수의 특이한 약점을 언급함.
- 예를 들어 사용자의 개인 정보 보호 전략을 고려하지 않거나, 가상의 상황과 실제 상황을 구분하는 데 어려움이 있었음.

### 한계 
- 사용된 이진 및 범주적 공개 변형 모델에서 탐지된 공개 범위는 동일하지 않아서 직접 비교의 어려움 발생.
- 연구 참가자 성비 차이가 있으며, 이는 일반 인구와 다름.

### 결론 
- 개인 정보를 pseudonymous online forums (예: Reddit)에 게시할 때, 사용자는 자기 공개의 이점을 지키면서 추상적인 위험을 균형 있게 다루기 어려움.
- NLP 기반 자기 공개 탐지 도구는 사용자들이 온라인에서 보안을 강화하는 방법으로 지속 가능성을 보여줌.

### KEYWORD 
- AI-assisted self-disclosure detection tools
- socio-technical gap
- F1 score
- categorical disclosure
- contextual understanding
- k-anonymity loss
- transformer-based model
- privacy mitigation strategies
- community guidelines

---

## INTRODUCTION

## 요약

- **배경**: 매일 수백만 명의 사람들이 Reddit과 같은 가명 온라인 포럼에 접속하여 자신의 신원 가방없이 비슷한 생각을 가진 타인과 연결하고 지지받는 안전한 공간을 찾고 있다.
- **정보 공개**: 사용자는 감정적 또는 정보적 지원을 찾을 때 개인 정보를 자발적으로 공개할 가능성이 있으며, 이는 가명 포럼에서 민감한 정보를 공개하는 경향과 연관된다.
- **위험성**: 자발적인 공개의 이점은 명확하지만, 그에 따른 잠재적 위험은 모호하고 추상적이다. 이는 부주의한 공유로 이어질 수 있으며, 후회의 감정과 재익명화 위험에 기여할 수 있다.
- **NLP 도구 및 연구 동기**: 자연어 처리(NLP) 도구가 사용자들이 위험한 자발적 공개를 인식하도록 도울 수 있다고 제안했으나, 실제 사용자를 대상으로 평가된 적은 없다. 사용자 의도와 필요를 고려하지 않으면, 이러한 도구는 기술적으로 가능하지만 사회적으로 필요하지 않은 결과를 낳는다.

### 연구 질문
- **RQ1**: 자발적 공개의 필요성과 위험 사이의 긴장감을 고려할 때, NLP 모델과의 상호작용이 사용자에게 잠재적 공개 위험을 어떻게 인식시킬 수 있는가?
- **RQ2**: NLP 모델의 피드백은 어떻게 구성되어야 하는가? 사용자의 공개 위험을 전달하는 데 유용한 텍스트의 세분화 수준은 무엇인가?
- **RQ3**: NLP 자발적 공개 탐지 모델은 어디에서 부족하며, 사용자 선호도에 더 잘 맞추기 위해 어떻게 개선할 수 있을까?

### 연구 방법
- 우리는 21명의 Reddit 사용자와 심층 면담 연구를 수행했다. 사용자들은 Dou et al. [27]의 최신 NLP 기반 자발적 공개 탐지 모델을 사용했으며, 이는 텍스트 범위 수준에서 특정 위험한 자발적 공개를 식별하는 기능이 있다.

### 결과
- 모델은 자발적 공개를 식별하는 데 완벽하지 않았지만, 참가자의 82%가 모델을 사용하길 원하거나 추천할 것이라고 응답했다. 참가자들은 모델이 자아 성찰을 촉진하고, 이전에 알지 못했던 위험을 약속하며, 공유하는 데 있어 불확실한 콘텐츠에 대해 결정하는 데 도움을 주었다고 평가했다.
- 참가자들은 더 많은 세분화된 출력을 선호했으며, 범주 레이블이 모델이 위험한 모든 공개를 식별하는 이유를 명확히 하는 데 도움이 되었다고 밝혔다. 또한, 위험 수준, 최악의 시나리오, 공개 위험을 줄이기 위한 재표현 제안에 대한 추가 설명 필요성을 언급했다.

### 개선 기회
- 참가자들은 모델이 게시 문맥과 공개 규범을 이해해야 하며, 사실과 비사실적 공개를 구분하고, 사용자가 기존의 개인 정보 보호 관리 전략을 고려해야 한다고 언급했다. 발견된 추가 자발적 공개 형식으로는 불법 또는 학대 활동, 약물 중독, 특정 사건 등이 있다.

### 결론 및 기여
- 자발적 공개 탐지 NLP 모델이 사용자에게 온라인에서의 재식별 위험을 인식하게 하고, 모델 출력을 효과적으로 제시하여 정보 및 정서적 지원을 요청할 때 공개의 이점과 위험을 균형 있게 고려하게 하는 방법을 설명했다.
- 우리는 NLP 기반 공개 탐지 도구 사용 시 고려해야 할 설계 요소를 제안하여 자발적 공개 관련 개인 정보 보호 위험 감소에 기여할 수 있는 방법을 제시했다.

## KEYWORDS
- pseudonymous
- self-disclosure
- natural language processing (NLP)
- privacy
- re-identification risks
- social-technical gap
- categorical disclosure model
- binary disclosure model

---

## REFERENCES

## 연구 요약 

본 연구에서는 온라인 자아 표현 및 개인 정보 보호와 관련된 여러 연구들을 종합적으로 다룹니다. 다양한 연구는 사용자의 자아 노출, 온라인 소통, 개인 정보 보호와 관련된 선택, AI의 역할 및 이로 인한 사회적 영향에 대해 심층적으로 조사하고 있습니다.

### 핵심 요점

- Mark S Ackerman의 연구는 CSCW에서 사회적 요구와 기술적 실행 가능성 간의 간극을 다룹니다.
- Alessandro Acquisti 외의 연구에서는 사용자들이 온라인에서 개인 정보 보호와 보안에 대해 하는 선택을 이해하고 지원을 제공하기 위한 "nudges"에 대해 설명합니다.
- Dhananjay Ashok과 Zachary C Lipton은 "PromptNER"를 통해 Named Entity Recognition을 위한 프롬프트 기법을 제안합니다.
- Tawfiq Ammari 외 연구진의 연구는 Reddit에서의 일회용 계정을 통한 부모 역할과 지원의 공개를 분석합니다.
- 다양한 논문에서 자아 노출, 사회적 지원, 안보 문제를 다룬 연구들이 포괄적으로 설명됩니다.

### 테이블 및 그래픽 포함

**A.1 테이블 A: 인구 통계**

| 인구 통계 | 여성 | 남성 | 논바이너리 | 총계 (N=21) |
|-----------|------|------|--------------|-------------|
| 나이      |      |      |              |             |
| 18-29     | 3 (25.0)  | 3 (42.9)  | 2 (100.0)     | 8           |
| 30-49     | 6 (50.0)  | 2 (28.6)  | 0            | 8           |
| 50-64     | 2 (16.7)  | 1 (14.3)  | 0            | 3           |
| 65세 이상 | 1 (8.3)   | 1 (14.3)  | 0            | 2           |

**A.2 테이블 B: 사용자 수정 결정 요약**

|             | 수용된 스팬 (495)  | 거부된 스팬 (356)  | 총계 (851) |
|-------------|------------------|------------------|------------|
| 수정됨      | 23% (114)      | 3.7% (13)       |            |
| 결정되지 않음| 5% (23)        | 2% (7)          | 3% (30)    |
| 수정하지 않음| 72% (357)      | 94.1% (335)     | 81% (692)  |

**A.3 테이블 C: 카테고리별 공개 범위 수용/거부 요약**

| 카테고리            | 거부율  | 수용율  | 수치 | 느낌표 |                  |
|--------------------|--------|--------|-----|------|------------------|
| 가족                | 35%    | 65%    | 158 |      |                  |
| 남편/여자친구      | 43%    | 57%    | 81  |      |                  |
| 건강                | 31%    | 69%    | 58  |      |                  |

### KEYWORD

- CSCW
- Nudges
- Named Entity Recognition (NER)
- Online self-disclosure
- AI privacy risks

이 요약은 연구의 주요 내용을 구조적으로 설명하며, 사용자의 온라인 자아 표현 및 개인 정보 보호 현대 문제를 다룹니다. 추가적인 정보 및 각각의 연구는 논문에서 확인할 수 있습니다.

---

## RESULTS

### 연구 질문 1: 모델과의 상호작용이 사용자에게 위험한 자기 공개 인식 및 완화 행동에 미치는 이점
- 21명 중 17명이 본 연구 외에도 모델을 사용하고 싶어 했으며, 이를 타인에게 추천할 의사를 나타냄.
- 사용자는 모델이 촉진한 자기 반성을 통해 다음과 같은 가치를 찾음:
  - (i) 작성 과정에서 인지하지 못한 또는 간과한 위험한 공개 내용을 포착.
  - (ii) 위험한 공개의 개념을 넓힘.
  - (iii) 공개 여부에 대한 결정을 내리는 데 도움.
- 그러나 사용자는 내용의 의미를 유지하면서 기재된 내용을 재구성하고 위험을 줄이는 방법에 대한 지원이 필요함을 발견함.

### 연구 질문 2: 분류 세분화의 영향
- 모델이 감지한 위험한 텍스트와 함께 제공된 정보의 세분화가 사용자 수용에 영향을 미쳤음.
- 사용자들은 분류적 공개 모델이 공개 스팬이 위험으로 감지된 이유를 이해하는 데 도움이 된다고 기술함.
- 높은 세분화의 분류가 사용자 수용에 긍정적인 영향을 미친 것으로 확인됨.

### 연구 질문 3: AI 기반 공개 감지 도구의 한계 및 개선 방안
- 사용자들은 모델의 출력이 자신들의 위험 완화 전략을 고려하지 않았을 때 가장 유용하지 않다고 평가함.
- 공개 카테고리가 포함되지 않은 중요한 내용도 있음.
- 모델은 맥락을 고려하지 않음으로써 감지된 공개의 유효성을 떨어뜨림.

### 모델이 감지한 자기 공개의 통계적 요약
| 감지된 공개 스팬 유형 | 수 | 비율 |
|-------------------|---|-----|
| 수용된 스팬 | 495 | 58% |
| 거부된 스팬 | 356 | 41.8% |

### 모델 감지 이슈 요약
| 공개 감지 스팬 문제 | 수용된 스팬(495) | 거부된 스팬(356) | 총 발생 건수(868) |
|----------------|----------------|----------------|----------------|
| 말이 안 됨         | 1 (0.2%)       | 115 (30.8%)    | 116 (13.4%)     |
| 맥락 부족         | 5 (1%)         | 28 (7.5%)      | 33 (3.8%)       |
| 사용자 선호와 불일치 | 8 (1.6%)       | 152 (40.8%)    | 160 (18.4%)     |
| 잘못된 카테고리 태그 | 33 (6.7%)      | 46 (12.3%)     | 79 (9.1%)       |

### 연구 결과 요약
- 모델은 비록 불완전했지만, 사용자들은 전반적으로 긍정적인 반응을 보임. 많은 사용자들이 모델의 유용성, 도움의 필요성을 느꼈음.
- 사용자들은 모델의 출력이 맥락을 고려하지 않았음에 실망함. 사용자들이 중요하게 여기는 공개의 종류와 관련된 결정을 내릴 수 있는 보다 직관적인 피드백을 원함. 

### 키워드
- RQ1
- RQ2
- RQ3
- disclosure detection
- self-disclosure
- model output
- granularity
- categorization

---

